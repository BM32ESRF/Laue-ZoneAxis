<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>laue.geometry API documentation</title>
<meta name="description" content="** Permet d&#39;appliquer des transformations geometriques. **
…" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>laue.geometry</code></h1>
</header>
<section id="section-intro">
<h2 id="permet-dappliquer-des-transformations-geometriques"><strong> Permet d'appliquer des transformations geometriques. </strong></h2>
<h2 id="notes">Notes</h2>
<p>Le module <code>numexpr</code> permet d'accelerer les calculs si il est installe.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python3

&#34;&#34;&#34;
** Permet d&#39;appliquer des transformations geometriques. **
----------------------------------------------------------

Notes
-----
Le module ``numexpr`` permet d&#39;accelerer les calculs si il est installe.
&#34;&#34;&#34;

import collections
import hashlib
import inspect
import math
import multiprocessing
import os

import cloudpickle
import numpy as np
try:
    import numexpr
except ImportError:
    numexpr = None
import sympy


__all__ = [&#34;Transformer&#34;, &#34;comb2ind&#34;, &#34;ind2comb&#34;]


class Compilator:
    &#34;&#34;&#34;
    Extrait et enregistre les equations brutes.

    Notes
    -----
    Les equations sont enregistrees de facon globale
    de sorte a eviter la recompilation entre chaque objet,
    et permet aussi d&#39;alleger la serialisation de ``Transformer``.
    &#34;&#34;&#34;
    def __init__(self):
        &#34;&#34;&#34;
        Genere le dictionaire a protee globale.
        &#34;&#34;&#34;
        if &#34;compiled_expressions&#34; not in globals():
            globals()[&#34;compiled_expressions&#34;] = {}

        self.load()

    def compile(self, parameters=None):
        &#34;&#34;&#34;
        ** Precalcul toutes les equations. **

        Parameters
        ----------
        parameters : dict, optional
            Les parametres donnes par la fonction ``laue.tools.parsing.extract_parameters``.
            Si ils sont fourni, l&#39;expression est encore un peu
            plus optimisee.
        &#34;&#34;&#34;
        names = [
            &#34;expr_cam_to_gnomonic&#34;,
            &#34;expr_gnomonic_to_cam&#34;,
            &#34;expr_thetachi_to_gnomonic&#34;,
            &#34;expr_gnomonic_to_thetachi&#34;,
            &#34;fct_dist_line&#34;,
            &#34;fct_hough&#34;,
            &#34;fct_inter_line&#34;]
        names = [n for n in names if n not in globals()[&#34;compiled_expressions&#34;]]

        for name in names:
            getattr(self, f&#34;get_{name}&#34;)()

        self.save() # On enregistre les grandes equations.

        if parameters is not None:
            assert isinstance(parameters, dict), (&#34;Les parametres doivent founis &#34;
                f&#34;dans un dictionaire, pas dans un {type(parameters).__name__}&#34;)
            assert set(parameters) == {&#34;dd&#34;, &#34;xbet&#34;, &#34;xgam&#34;, &#34;xcen&#34;, &#34;ycen&#34;, &#34;pixelsize&#34;}, \
                (&#34;Les clefs doivent etres &#39;dd&#39;, &#39;xbet&#39;, &#39;xgam&#39;, &#39;xcen&#39;, &#39;ycen&#39; et &#39;pixelsize&#39;. &#34;
                f&#34;Or les clefs sont {set(parameters)}.&#34;)
            assert all(isinstance(v, (float, int)) for v in parameters.values()), \
                &#34;La valeurs des parametres doivent toutes etre des nombres.&#34;

            hash_param = self._hash_parameters(parameters)
            contants = {self.dd: parameters[&#34;dd&#34;], # C&#39;est qu&#39;il est tant de faire de l&#39;optimisation.
                        self.xcen: parameters[&#34;xcen&#34;],
                        self.ycen: parameters[&#34;ycen&#34;],
                        self.xbet: parameters[&#34;xbet&#34;],
                        self.xgam: parameters[&#34;xgam&#34;],
                        self.pixelsize: parameters[&#34;pixelsize&#34;]}
            self._fcts_cam_to_gnomonic[hash_param] = _Lambdify(
                    args=[self.x_cam, self.y_cam],
                    expr=self.get_expr_cam_to_gnomonic().get_expr().subs(contants),
                    modules=&#34;numexpr&#34;)
            self._fcts_gnomonic_to_cam[hash_param] = _Lambdify(
                    args=[self.x_gnom, self.y_gnom],
                    expr=self.get_expr_gnomonic_to_cam().get_expr().subs(contants),
                    modules=&#34;numexpr&#34;)

    def get_expr_cam_to_gnomonic(self):
        &#34;&#34;&#34;
        ** Equation permetant de passer de la camera au plan gnomonic. **
        &#34;&#34;&#34;
        if &#34;expr_cam_to_gnomonic&#34; in globals()[&#34;compiled_expressions&#34;]:
            return globals()[&#34;compiled_expressions&#34;][&#34;expr_cam_to_gnomonic&#34;]

        # Expresion du vecteur OP.
        o_op = self.dd * self.ck # Vecteur OO&#39;.
        op_p = self.pixelsize * ((self.x_cam-self.xcen)*self.ci + (self.y_cam-self.ycen)*self.cj) # Vecteur O&#39;P
        o_p = o_op + op_p # Relation de Chasles.

        # Recherche des droites normales au plan christalin.
        u_f = o_p.normalized() # Vecteur norme du rayon diffracte u_f.
        u_q = u_f - self.u_i # Relation de reflexion.

        # Recherche du vecteur O&#39;&#39;&#39;P&#39;.
        oppp_pp = u_q / u_q.dot(self.gk) # Point d&#39;intersection avec le plan gnomonic. (Normalisation de l&#39;axe gk.)

        # Projection dans le plan gnomonic pour remonter a x_g, y_g
        oppp_pp = sympy.simplify(oppp_pp)
        x_g = oppp_pp.dot(self.gi) # Coordonnees en mm axe x du plan gnomonic.
        y_g = oppp_pp.dot(self.gj) # Coordonnees en mm axe y du plan gnomonic.

        globals()[&#34;compiled_expressions&#34;][&#34;expr_cam_to_gnomonic&#34;] = _Lambdify(
            args=[self.x_cam, self.y_cam, self.dd, self.xcen, self.ycen, self.xbet, self.xgam, self.pixelsize],
            expr=[x_g, y_g], # Les imprecisions de calculs donnent parfois des complexes!
            modules=&#34;numexpr&#34;) # On l&#39;enregistre une bonne fois pour toutes.
        return globals()[&#34;compiled_expressions&#34;][&#34;expr_cam_to_gnomonic&#34;]

    def get_expr_gnomonic_to_cam(self):
        &#34;&#34;&#34;
        ** Equation permetant de passer de l&#39;espace gnomonic a celui de la camera. **
        &#34;&#34;&#34;
        if &#34;expr_gnomonic_to_cam&#34; in globals()[&#34;compiled_expressions&#34;]:
            return globals()[&#34;compiled_expressions&#34;][&#34;expr_gnomonic_to_cam&#34;]

        # Recherche du vecteur u_q.
        o_oppp = self.gk # Vecteur OO&#39;&#39;&#39; == gk car le plan gnomonic est tangent a la shere unitaire.
        u_q = o_oppp + (self.x_gnom*self.gi + self.y_gnom*self.gj) # Vecteur non normalise de la normale au plan christalin.
        u_q = u_q.normalized() # Normale unitaire au plan christalin.

        # Lois de la reflexion.
        u_f = self.u_i - 2*u_q.dot(self.u_i)*u_q # Vecteur unitaire reflechi.
        # u_f = sympy.simplify(u_f) # Permet d&#39;accelerer les calculs par la suite.

        # Expression du vecteur O&#39;&#39;P.
        opp_op = self.pixelsize * (self.xcen*self.ci + self.ycen*self.cj) # Vecteur O&#39;&#39;O&#39;.
        o_op = self.dd * self.ck # Vecteur OO&#39;.
        op_o = -o_op # Vecteur O&#39;O.
        camera_plane = sympy.Plane(o_op, normal_vector=self.ck) # Plan de la camera.
        refl_ray = sympy.Line([0, 0, 0], u_f) # Rayon reflechi.
        o_p = sympy.Matrix(camera_plane.intersection(refl_ray).pop())
        opp_p = opp_op + op_o + o_p # Relation de Chasles.

        # Projection dans le plan de la camera pour remonter a x_c, y_c
        opp_p = sympy.simplify(opp_p)
        x_c = opp_p.dot(self.ci) / self.pixelsize # Coordonnees en pxl axe x de la camera.
        y_c = opp_p.dot(self.cj) / self.pixelsize # Coordonnees en pxl axe y de la camera.

        globals()[&#34;compiled_expressions&#34;][&#34;expr_gnomonic_to_cam&#34;] = _Lambdify(
            args=[self.x_gnom, self.y_gnom, self.dd, self.xcen, self.ycen, self.xbet, self.xgam, self.pixelsize],
            expr=[x_c, y_c],
            modules=&#34;numexpr&#34;) # On l&#39;enregistre une bonne fois pour toutes.
        return globals()[&#34;compiled_expressions&#34;][&#34;expr_gnomonic_to_cam&#34;]

    def get_expr_thetachi_to_gnomonic(self):
        &#34;&#34;&#34;
        ** Equation permetant de passer de theta chi au plan gnomonic. **
        &#34;&#34;&#34;
        if &#34;expr_thetachi_to_gnomonic&#34; in globals()[&#34;compiled_expressions&#34;]:
            return globals()[&#34;compiled_expressions&#34;][&#34;expr_thetachi_to_gnomonic&#34;]

        # Expresion du rayon reflechit en fonction des angles.
        rot_refl = sympy.rot_axis1(self.chi) @ sympy.rot_axis2(2*self.theta)

        # Recherche des droites normales au plan christalin.
        u_f = rot_refl @ self.u_i # Vecteur norme du rayon diffracte u_f.
        u_q = u_f - self.u_i # Relation de reflexion.

        # Recherche du vecteur O&#39;&#39;&#39;P&#39;.
        oppp_pp = u_q / u_q.dot(self.gk) # Point d&#39;intersection avec le plan gnomonic. (Normalisation de l&#39;axe gk.)

        # Projection dans le plan gnomonic pour remonter a x_g, y_g
        oppp_pp = sympy.simplify(oppp_pp)
        x_g = oppp_pp.dot(self.gi) # Coordonnees en mm axe x du plan gnomonic.
        y_g = oppp_pp.dot(self.gj) # Coordonnees en mm axe y du plan gnomonic.

        globals()[&#34;compiled_expressions&#34;][&#34;expr_thetachi_to_gnomonic&#34;] = _Lambdify(
            args=[self.theta, self.chi],
            expr=[x_g, y_g], # Les imprecisions de calculs donnent parfois des complexes!
            modules=&#34;numexpr&#34;) # On l&#39;enregistre une bonne fois pour toutes.
        return globals()[&#34;compiled_expressions&#34;][&#34;expr_thetachi_to_gnomonic&#34;]

    def get_expr_gnomonic_to_thetachi(self):
        &#34;&#34;&#34;
        ** Equation permetant de passer du plan gnomonic a la representation theta chi. **
        &#34;&#34;&#34;
        if &#34;expr_gnomonic_to_thetachi&#34; in globals()[&#34;compiled_expressions&#34;]:
            return globals()[&#34;compiled_expressions&#34;][&#34;expr_gnomonic_to_thetachi&#34;]

        # Recherche du vecteur u_q.
        o_oppp = self.gk # Vecteur OO&#39;&#39;&#39; == gk car le plan gnomonic est tangent a la shere unitaire.
        u_q = o_oppp + (self.x_gnom*self.gi + self.y_gnom*self.gj) # Vecteur non normalise de la normale au plan christalin.
        u_q = u_q.normalized() # Normale unitaire au plan christalin.

        # Lois de la reflexion.
        u_f = self.u_i - 2*u_q.dot(self.u_i)*u_q # Vecteur unitaire reflechi.

        # Projection et normalisation dans le plan normal a x pour acceder a chi.
        # Projection et normalisation dans le plan normal a y pour acceder a theta.
        u_f = sympy.simplify(u_f) # Permet d&#39;accelerer les calculs par la suite.
        chi = sympy.asin(u_f.dot(self.ry) / (u_f.dot(self.rz)**2 + u_f.dot(self.ry)**2))
        theta = sympy.acos(u_f.dot(self.rx) / (u_f.dot(self.rx)**2 + u_f.dot(self.rz)**2)) / 2

        globals()[&#34;compiled_expressions&#34;][&#34;expr_gnomonic_to_thetachi&#34;] = _Lambdify(
            args=[self.x_gnom, self.y_gnom],
            expr=[theta, chi], # Les imprecisions de calculs donnent parfois des complexes!
            modules=&#34;numexpr&#34;) # On l&#39;enregistre une bonne fois pour toutes.
        return globals()[&#34;compiled_expressions&#34;][&#34;expr_gnomonic_to_thetachi&#34;]

    def get_fct_dist_line(self):
        &#34;&#34;&#34;
        ** Equation de projection de points sur une droite. **
        &#34;&#34;&#34;
        if &#34;fct_dist_line&#34; in globals()[&#34;compiled_expressions&#34;]:
            return globals()[&#34;compiled_expressions&#34;][&#34;fct_dist_line&#34;]

        # Creation de la droite.
        theta, dist, x, y = sympy.symbols(&#34;theta alpha x y&#34;, real=True)
        p = sympy.Point(dist*sympy.cos(theta), dist*sympy.sin(theta)) # Point appartenant a la droite.
        op = sympy.Line(sympy.Point(0, 0), p) # Droite normale a la droite principale.
        line = op.perpendicular_line(p) # C&#39;est la droite principale.

        # Projection des points.
        distance = line.distance(sympy.Point(x, y)) # La distance entre la droite et un point.
        distance = sympy.simplify(distance)

        # Vectorisation de l&#39;expression.
        globals()[&#34;compiled_expressions&#34;][&#34;fct_dist_line&#34;] = _Lambdify([theta, dist, x, y], distance, modules=&#34;numexpr&#34;)
        return globals()[&#34;compiled_expressions&#34;][&#34;fct_dist_line&#34;]

    def get_fct_hough(self):
        &#34;&#34;&#34;
        ** Equation pour la transformee de hough. **
        &#34;&#34;&#34;
        if &#34;fct_hough&#34; in globals()[&#34;compiled_expressions&#34;]:
            return globals()[&#34;compiled_expressions&#34;][&#34;fct_hough&#34;]

        xa, ya, xb, yb = sympy.symbols(&#34;x_a y_a x_b y_b&#34;, real=True)
        u = sympy.Matrix([xa-xb, ya-yb]).normalized()
        x = sympy.Matrix([1, 0])

        # Calcul de la distance entre la droite et l&#39;origine.
        d1 = sympy.Line(sympy.Point(xa, ya), sympy.Point(xb, yb)) # C&#39;est la droite passant par les 2 points.
        dist = d1.distance(sympy.Point(0, 0)) # La distance separant l&#39;origine de la droite.
        dist = sympy.simplify(dist)

        # Calcul de l&#39;angle entre l&#39;axe horizontal et la droite.
        p = d1.projection(sympy.Point(0, 0)) # Le point ou la distance entre ce point de la droite et l&#39;origine est minimale.
        n = p / sympy.sqrt(p.x**2 + p.y**2) # On normalise le point.
        theta_abs = sympy.acos(n.x) # La valeur absolue de theta.
        theta_sign = sympy.sign(n.y) # Si il est negatif c&#39;est que theta &lt; 0, si il est positif alors theta &gt; 0
        theta = theta_abs * theta_sign # Compris entre -pi et +pi
        theta = sympy.simplify(theta)

        # Vectorisation des expressions.
        globals()[&#34;compiled_expressions&#34;][&#34;fct_hough&#34;] = _Lambdify([xa, ya, xb, yb], [theta, dist], modules=&#34;numexpr&#34;)
        return globals()[&#34;compiled_expressions&#34;][&#34;fct_hough&#34;]

    def get_fct_inter_line(self):
        &#34;&#34;&#34;
        ** Equation d&#39;intersection entre 2 droites. **
        &#34;&#34;&#34;
        if &#34;fct_inter_line&#34; in globals()[&#34;compiled_expressions&#34;]:
            return globals()[&#34;compiled_expressions&#34;][&#34;fct_inter_line&#34;]

        # Creation des 2 droites.
        theta_1, dist_1, theta_2, dist_2 = sympy.symbols(&#34;theta_1, dist_1, theta_2, dist_2&#34;, real=True)
        p1 = sympy.Point(dist_1*sympy.cos(theta_1), dist_1*sympy.sin(theta_1)) # Point appartenant a la premiere droite.
        p2 = sympy.Point(dist_2*sympy.cos(theta_2), dist_2*sympy.sin(theta_2)) # Point appartenant a la seconde droite.
        op1 = sympy.Line(sympy.Point(0, 0), p1) # Droite normale a la premiere droite.
        op2 = sympy.Line(sympy.Point(0, 0), p2) # Droite normale a la deuxieme droite.
        line1 = op1.perpendicular_line(p1) # La premiere droite.
        line2 = op2.perpendicular_line(p2) # La seconde droite.

        # Calcul des coordonnes du point d&#39;intersection.
        point = line1.intersection(line2)[0]
        inter_x = sympy.simplify(point.x)
        inter_y = sympy.simplify(point.y)

        # Vectorisation des expressions.
        globals()[&#34;compiled_expressions&#34;][&#34;fct_inter_line&#34;] = _Lambdify(
            [theta_1, dist_1, theta_2, dist_2], [inter_x, inter_y], modules=&#34;numexpr&#34;)
        return globals()[&#34;compiled_expressions&#34;][&#34;fct_inter_line&#34;]

    def _hash(self):
        &#34;&#34;&#34;
        ** Retourne le hash de ce code. **
        &#34;&#34;&#34;
        return hashlib.md5(
            inspect.getsource(Compilator).encode(encoding=&#34;utf-8&#34;)
            ).hexdigest()

    def save(self):
        &#34;&#34;&#34;
        ** Enregistre un fichier contenant les expressions. **

        Enregistre seulement ce qui est present dans ``globals()[&#34;compiled_expressions&#34;]``.
        N&#39;ecrase pas l&#39;ancien contenu.
        &#34;&#34;&#34;
        dirname = os.path.dirname(os.path.abspath(__file__))
        file = os.path.join(dirname, &#34;geometry.data&#34;)
        self.load() # Recuperation du contenu du fichier.
        content = {
            &#34;hash&#34;: self._hash(),
            &#34;expr&#34;: globals()[&#34;compiled_expressions&#34;]
            }
        with open(file, &#34;wb&#34;) as f:
            cloudpickle.dump(content, f)

    def load(self):
        &#34;&#34;&#34;
        ** Charge si il existe, le fichier contenant les expressions. **

        Deverse les expressions dans le dictionaire: ``globals()[&#34;compiled_expressions&#34;]``.
        &#34;&#34;&#34;
        dirname = os.path.dirname(os.path.abspath(__file__))
        file = os.path.join(dirname, &#34;geometry.data&#34;)
        
        # if os.path.exists(file):
        #     with open(file, &#34;rb&#34;) as f:
        #         try:
        #             content = cloudpickle.load(f)
        #         except ValueError: # Si c&#39;est pas le bon protocol
        #             content = {&#34;hash&#34;: None}
        #     if content[&#34;hash&#34;] == self._hash(): # Si les donnees sont a jour.
        #         globals()[&#34;compiled_expressions&#34;] = {**globals()[&#34;compiled_expressions&#34;], **content[&#34;expr&#34;]}
        return globals()[&#34;compiled_expressions&#34;]


class Transformer(Compilator):
    &#34;&#34;&#34;
    Permet d&#39;effectuer des transformations geometrique comme jongler
    entre l&#39;espace de la camera et l&#39;espace gnomonique ou encore
    s&#39;ammuser avec la transformee de Hough.
    &#34;&#34;&#34;
    def __init__(self):
        # Les constantes.
        self.dd = sympy.Symbol(&#34;dd&#34;, real=True, positive=True) # Distance entre l&#39;origine et le plan de la camera en mm.
        self.xcen, self.ycen = sympy.symbols(&#34;xcen ycen&#34;, real=True) # Position du point d&#39;incidence normale en pxl par rapport au repere de la camera.
        self.xbet, self.xgam = sympy.symbols(&#34;beta gamma&#34;, real=True) # Rotation autour x camera, Rotation autour axe incidence normale.
        self.pixelsize = sympy.Symbol(&#34;alpha&#34;, real=True, positive=True) # Taille des pixels en mm/pxl.

        # Les variables.
        self.x_cam, self.y_cam = sympy.symbols(&#34;x_cam y_cam&#34;, real=True, positive=True) # Position du pxl dans le repere du plan de la camera.
        self.x_gnom, self.y_gnom = sympy.symbols(&#34;x_gnom y_gnom&#34;, real=True) # Position des points dans le plan gnomonic.
        self.theta, self.chi = sympy.symbols(&#34;theta chi&#34;, real=True) # Les angles decrivant le rayon reflechit.

        # Expression des elements du model.
        self.rx = sympy.Matrix([1, 0, 0])
        self.ry = sympy.Matrix([0, 1, 0])
        self.rz = sympy.Matrix([0, 0, 1])

        self.u_i = self.rx # Le rayon de lumiere incident norme parallele a l&#39;axe X dans le repere du cristal.

        self.rot_camera = sympy.rot_axis2(-self.xbet) @ sympy.rot_axis3(self.xgam) # Rotation globale de la camera par rapport au cristal.
        self.ci = self.rot_camera @ -self.ry # Vecteur Xcamera.
        self.cj = self.rot_camera @ self.rx # Vecteur Ycamera.
        self.ck = self.rot_camera @ self.rz # Vecteur Zcamera normal au plan de la camera.

        self.rot_gnom = sympy.rot_axis2(-sympy.pi/4) # Rotation du repere de plan gnomonic par rapport au repere du cristal.
        self.gi = self.rot_gnom @ self.rz # Vecteur Xgnomonic.
        self.gj = self.rot_gnom @ self.ry # Vecteur Ygnomonic.
        self.gk = self.rot_gnom @ -self.rx # Vecteur Zgnomonic normal au plan gnomonic.

        Compilator.__init__(self) # Globalisation des expressions.

        # Les memoires tampon.
        self._fcts_cam_to_gnomonic = collections.defaultdict(lambda: 0) # Fonctions vectorisees avec seulement f(x_cam, y_cam), les parametres sont deja remplaces.
        self._fcts_gnomonic_to_cam = collections.defaultdict(lambda: 0) # Fonctions vectorisees avec seulement f(x_gnom, y_gnom), les parametres sont deja remplaces.
        self._parameters_memory = {} # Permet d&#39;eviter de relire le dictionaire des parametres a chaque fois.

    def cam_to_gnomonic(self, pxl_x, pxl_y, parameters):
        &#34;&#34;&#34;
        ** Passe des points de la camera dans un plan gnomonic. **

        Notes
        -----
        * Les calculs sont effectues avec des float32 pour des histoire de performance.
        * Cette methode va 1.8 a 3.3 fois plus vite que celle de LaueTools.
        * Contrairement a LaueTools, cette methode prend en charge les vecteurs a n dimenssions.

        Parameters
        ----------
        pxl_x : float, int ou np.ndarray
            Coordonnee.s du.des pxl.s selon l&#39;axe x dans le repere de la camera. (en pxl)
        pxl_y : float, int ou np.ndarray
            Coordonnee.s du.des pxl.s selon l&#39;axe y dans le repere de la camera. (en pxl)
        parameters : dict
            Le dictionaire issue de la fonction ``laue.tools.parsing.extract_parameters``.

        Returns
        -------
        float ou np.ndarray
            Le.s coordonnee.s x puis y du.des point.s dans le plan gnomonic eprimee.s en mm.
            Les dimenssions du tableau de sortie sont les memes que celle du tableau d&#39;entree.
            shape de sortie = (2, *shape_d_entree)

        Examples
        -------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue.geometry import Transformer
        &gt;&gt;&gt; from laue.tools.parsing import extract_parameters
        &gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
        &gt;&gt;&gt; transformer = Transformer()
        &gt;&gt;&gt; x_cam, y_cam = np.linspace(0, 2048, 5), np.linspace(0, 2048, 5)
        &gt;&gt;&gt;
        &gt;&gt;&gt; transformer.cam_to_gnomonic(x_cam, y_cam, parameters).astype(np.float16)
        array([[-0.5127, -0.3064,  0.    ,  0.1676,  0.1342],
               [ 0.4033,  0.287 , -0.    , -0.4832, -0.9385]], dtype=float16)
        &gt;&gt;&gt;
        &#34;&#34;&#34;
        assert isinstance(pxl_x, (float, int, np.ndarray)), \
            f&#34;&#39;pxl_x&#39; can not be of type {type(pxl_x).__name__}.&#34;
        assert isinstance(pxl_y, (float, int, np.ndarray)), \
            f&#34;&#39;pxl_y&#39; can not be of type {type(pxl_y).__name__}.&#34;
        assert type(pxl_x) == type(pxl_y), \
            f&#34;Les 2 types sont differents: {type(pxl_x).__name__} vs {type(pxl_y).__name__}.&#34;
        if isinstance(pxl_x, np.ndarray):
            assert pxl_x.shape == pxl_y.shape, \
                f&#34;Ils n&#39;ont pas le meme taille: {pxl_x.shape} vs {pxl_y.shape}.&#34;
        assert isinstance(parameters, dict), (&#34;Les parametres doivent founis &#34;
            f&#34;dans un dictionaire, pas dans un {type(parameters).__name__}&#34;)
        assert set(parameters) == {&#34;dd&#34;, &#34;xbet&#34;, &#34;xgam&#34;, &#34;xcen&#34;, &#34;ycen&#34;, &#34;pixelsize&#34;}, \
            (&#34;Les clefs doivent etres &#39;dd&#39;, &#39;xbet&#39;, &#39;xgam&#39;, &#39;xcen&#39;, &#39;ycen&#39; et &#39;pixelsize&#39;. &#34;
            f&#34;Or les clefs sont {set(parameters)}.&#34;)
        assert all(isinstance(v, (float, int)) for v in parameters.values()), \
            &#34;La valeurs des parametres doivent toutes etre des nombres.&#34;

        if isinstance(pxl_x, np.ndarray):
            pxl_x, pxl_y = pxl_x.astype(np.float32, copy=False), pxl_y.astype(np.float32, copy=False)
        else:
            pxl_x, pxl_y = np.float32(pxl_x), np.float32(pxl_y)

        hash_param = self._hash_parameters(parameters) # Recuperation de la &#39;signature&#39; des parametres.
        optimized_func = self._fcts_cam_to_gnomonic[hash_param] # On regarde si il y a une fonction deja optimisee.

        if isinstance(optimized_func, int): # Si il n&#39;y a pas de fonction optimisee.
            nbr_access = optimized_func # Ce qui est enregistre et le nombre de fois que l&#39;on a chercher a y acceder.
            self._fcts_cam_to_gnomonic[hash_param] += 1 # Comme on cherche a y acceder actuelement, on peut incrementer le compteur.
            if nbr_access + 1 == 4: # Si c&#39;est la 4 eme fois qu&#39;on accede a la fonction.
                self.compile(parameters) # On optimise la fonction.
            else: # Si ce n&#39;est pas encore le moment de perdre du temps a optimiser.
                return self.get_expr_cam_to_gnomonic()(pxl_x, pxl_y,
                    parameters[&#34;dd&#34;], parameters[&#34;xcen&#34;], parameters[&#34;ycen&#34;],
                    parameters[&#34;xbet&#34;], parameters[&#34;xgam&#34;], parameters[&#34;pixelsize&#34;])

        return self._fcts_cam_to_gnomonic[hash_param](pxl_x, pxl_y)

    def dist_line(self, theta_vect, dist_vect, x_vect, y_vect):
        &#34;&#34;&#34;
        ** Calcul les distances projetees des points sur une droite. **

        Notes
        -----
        Pour des raisons de performances, travail avec des float32.

        Parameters
        ----------
        theta_vect : np.ndarray
            Les angles des droites normales aux droites principales.
            shape = ``(*nbr_droites)``
        dist_vect : np.ndarray
            Les distances entre les droites et l&#39;origine.
            shape = ``(*nbr_droites)``
        x_vect : np.ndarray
            L&#39;ensemble des coordonnees x des points.
            shape = ``(*nbr_points)``
        y_vect : np.ndarray
            L&#39;ensemble des coordonnees y des points.
            shape = ``(*nbr_points)``

        Returns
        -------
        np.ndarray
            Les distances des projetees des points sur chacunes des droites.
            shape = ``(*nbr_droites, *nbr_points)``

        Examples
        --------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue.geometry import Transformer
        &gt;&gt;&gt; from laue.tools.parsing import extract_parameters
        &gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
        &gt;&gt;&gt; transformer = Transformer()
        &gt;&gt;&gt;
        &gt;&gt;&gt; lines = (np.array([0, np.pi/2]), np.array([1, 1])) # Horizontale et verticale passant par (1, 1)
        &gt;&gt;&gt; points = (np.array([0, 1, 3, 0]), np.array([0, 1, 3, 1]))
        &gt;&gt;&gt; np.round(transformer.dist_line(*lines, *points))
        array([[1., 0., 2., 1.],
               [1., 0., 2., 0.]], dtype=float32)
        &gt;&gt;&gt;
        &#34;&#34;&#34;
        assert isinstance(theta_vect, np.ndarray), \
            f&#34;&#39;theta_vect&#39; has to be of type np.ndarray, not {type(theta_vect).__name__}.&#34;
        assert isinstance(dist_vect, np.ndarray), \
            f&#34;&#39;dist_vect&#39; has to be of type np.ndarray, not {type(dist_vect).__name__}.&#34;
        assert theta_vect.shape == dist_vect.shape, \
            f&#34;Les 2 parametres de droite doivent avoir la meme taille: {theta_vect.shape} vs {dist_vect.shape}.&#34;
        assert isinstance(x_vect, np.ndarray), \
            f&#34;&#39;x_vect&#39; has to be of type np.ndarray, not {type(x_vect).__name__}.&#34;
        assert isinstance(y_vect, np.ndarray), \
            f&#34;&#39;y_vect&#39; has to be of type np.ndarray, not {type(y_vect).__name__}.&#34;
        assert x_vect.shape == y_vect.shape, \
            f&#34;Les 2 coordonnees des points doivent avoir la meme shape: {x_vect.shape} vs {y_vect.shape}.&#34;

        theta_vect, dist_vect = theta_vect.astype(np.float32, copy=False), dist_vect.astype(np.float32, copy=False)
        x_vect, y_vect = x_vect.astype(np.float32, copy=False), y_vect.astype(np.float32, copy=False)

        nbr_droites = theta_vect.shape
        nbr_points = x_vect.shape

        # Ca ne vaut pas le coup de paralleliser car c&#39;est tres rapide.
        func = self.get_fct_dist_line()
        result = np.array([func(theta, dist, x_vect, y_vect)
                           for theta, dist
                           in zip(theta_vect.ravel(), dist_vect.ravel())
                          ], dtype=np.float32).reshape((*nbr_droites, *nbr_points))
        return result

    def gnomonic_to_cam(self, gnom_x, gnom_y, parameters):
        &#34;&#34;&#34;
        ** Passe des points du plan gnomonic vers la camera. **

        Parameters
        ----------
        gnom_x : float ou np.ndarray
            Coordonnee.s du.des point.s selon l&#39;axe x du repere du plan gnomonic. (en mm)
        gnom_y : float ou np.ndarray
            Coordonnee.s du.des point.s selon l&#39;axe y du repere du plan gnomonic. (en mm)
        parameters : dict
            Le dictionaire issue de la fonction ``laue.tools.parsing.extract_parameters``.

        Returns
        -------
        coords : np.ndarray
            * Le.s coordonnee.s x puis y du.des point.s dans le plan de la camera. (en pxl)
            * shape = (2, ...)

        Examples
        -------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue.geometry import Transformer
        &gt;&gt;&gt; from laue.tools.parsing import extract_parameters
        &gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
        &gt;&gt;&gt; transformer = Transformer()
        &gt;&gt;&gt; gnom_x, gnom_y = np.random.normal(size=(2, 10, 4))
        &gt;&gt;&gt;
        &gt;&gt;&gt; transformer.gnomonic_to_cam(gnom_x, gnom_y, parameters).shape
        (2, 10, 4)
        &gt;&gt;&gt; transformer.gnomonic_to_cam(.0, .0, parameters)
        array([1024., 1024.])
        &gt;&gt;&gt;
        &#34;&#34;&#34;
        assert isinstance(gnom_x, (float, int, np.ndarray)), \
            f&#34;&#39;gnom_x&#39; can not be of type {type(gnom_x).__name__}.&#34;
        assert isinstance(gnom_y, (float, int, np.ndarray)), \
            f&#34;&#39;gnom_y&#39; can not be of type {type(gnom_y).__name__}.&#34;
        assert type(gnom_x) == type(gnom_y), \
            f&#34;Les 2 types sont differents: {type(gnom_x).__name__} vs {type(gnom_y).__name__}.&#34;
        if isinstance(gnom_x, np.ndarray):
            assert gnom_x.shape == gnom_y.shape, \
                f&#34;Ils n&#39;ont pas la meme taille: {gnom_x.shape} vs {gnom_y.shape}.&#34;
        assert isinstance(parameters, dict), (&#34;Les parametres doivent founis &#34;
            f&#34;dans un dictionaire, pas dans un {type(parameters).__name__}&#34;)
        assert set(parameters) == {&#34;dd&#34;, &#34;xbet&#34;, &#34;xgam&#34;, &#34;xcen&#34;, &#34;ycen&#34;, &#34;pixelsize&#34;}, \
            (&#34;Les clefs doivent etres &#39;dd&#39;, &#39;xbet&#39;, &#39;xgam&#39;, &#39;xcen&#39;, &#39;ycen&#39; et &#39;pixelsize&#39;. &#34;
            f&#34;Or les clefs sont {set(parameters)}.&#34;)
        assert all(isinstance(v, (float, int)) for v in parameters.values()), \
            &#34;La valeurs des parametres doivent toutes etre des nombres.&#34;

        if isinstance(gnom_x, np.ndarray):
            gnom_x, gnom_y = gnom_x.astype(np.float32, copy=False), gnom_y.astype(np.float32, copy=False)
        else:
            gnom_x, gnom_y = np.float32(gnom_x), np.float32(gnom_y)

        hash_param = self._hash_parameters(parameters) # Recuperation de la &#39;signature&#39; des parametres.
        optimized_func = self._fcts_gnomonic_to_cam[hash_param] # On regarde si il y a une fonction deja optimisee.

        if isinstance(optimized_func, int): # Si il n&#39;y a pas de fonction optimisee.
            nbr_access = optimized_func # Ce qui est enregistre et le nombre de fois que l&#39;on a chercher a y acceder.
            self._fcts_gnomonic_to_cam[hash_param] += 1 # Comme on cherche a y acceder actuelement, on peut incrementer le compteur.
            if nbr_access + 1 == 4: # Si c&#39;est la 4 eme fois qu&#39;on accede a la fonction.
                self.compile(parameters) # On optimise la fonction.
            else: # Si ce n&#39;est pas encore le moment de perdre du temps a optimiser.
                return self.get_expr_gnomonic_to_cam()(gnom_x, gnom_y,
                    parameters[&#34;dd&#34;], parameters[&#34;xcen&#34;], parameters[&#34;ycen&#34;],
                    parameters[&#34;xbet&#34;], parameters[&#34;xgam&#34;], parameters[&#34;pixelsize&#34;])

        return self._fcts_gnomonic_to_cam[hash_param](gnom_x, gnom_y)

    def hough(self, x_vect, y_vect):
        r&#34;&#34;&#34;
        ** Transformee de hough avec des droites. **

        Note
        ----
        * Pour des raisons de performances, les calculs se font sur des float32.
        * Les indices sont agences selon l&#39;ordre defini par la fonction ``comb2ind``.

        Parameters
        ----------
        x_vect : np.ndarray
            L&#39;ensemble des coordonnees x des points de shape: (*over_dims, nbr_points)
        y_vect : np.ndarray
            L&#39;ensemble des coordonnees y des points de shape: (*over_dims, nbr_points)

        Returns
        -------
        theta : np.ndarray
            * Les angles au sens trigomometrique des vecteurs reliant l&#39;origine
            ``O`` (0, 0) au point ``P`` appartenant a la droite tel que ``||OP||``
            soit la plus petite possible.
            * theta € [-pi, pi]
            * shape = ``(*over_dims, n*(n-1)/2)``
        dist : np.ndarray
            * Ce sont les normes des vecteur ``OP``.
            * dist € [0, +oo].
            * shape = ``(*over_dims, n*(n-1)/2)``
        * Ces 2 grandeurs sont concatenees dans une seule array de
        shape = ``(2, *over_dims, n*(n-1)/2)``

        Examples
        --------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue import geometry
        &gt;&gt;&gt; transformer = geometry.Transformer()
        &gt;&gt;&gt; x, y = np.random.normal(size=(2, 6))
        &gt;&gt;&gt; transformer.hough(x, y).shape
        (2, 15)
        &gt;&gt;&gt;
        &gt;&gt;&gt; x, y = np.random.normal(size=(2, 4, 5, 6))
        &gt;&gt;&gt; transformer.hough(x, y).shape
        (2, 4, 5, 15)
        &gt;&gt;&gt; 
        &#34;&#34;&#34;
        assert isinstance(x_vect, np.ndarray), \
            f&#34;&#39;x_vect&#39; has to be of type np.ndarray, not {type(x_vect).__name__}.&#34;
        assert isinstance(y_vect, np.ndarray), \
            f&#34;&#39;y_vect&#39; has to be of type np.ndarray, not {type(y_vect).__name__}.&#34;
        assert x_vect.shape == y_vect.shape, \
            f&#34;Les 2 entrees doivent avoir la meme taille: {x_vect.shape} vs {y_vect.shape}.&#34;

        n = x_vect.shape[-1]
        x_vect, y_vect = x_vect.astype(np.float32, copy=False), y_vect.astype(np.float32, copy=False)

        xa = np.concatenate([np.repeat(x_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
        ya = np.concatenate([np.repeat(y_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
        xb = np.concatenate([x_vect[..., i+1:] for i in range(n-1)], axis=-1)
        yb = np.concatenate([y_vect[..., i+1:] for i in range(n-1)], axis=-1)

        return np.nan_to_num(
            self.get_fct_hough()(xa, ya, xb, yb),
            copy=False,
            nan=0.0)

    def hough_reduce(self, theta_vect, dist_vect, *, nbr=4, tol=0.018):
        &#34;&#34;&#34;
        ** Regroupe des droites ressemblantes. **

        Notes
        -----
        * Cette methode est concue pour traiter les donnees issues de ``laue.geometry.Transformer.hough``.
        * La metrique utilise est la distance euclidiene sur un cylindre ferme sur theta.
        * En raison de performance et de memoire, les calculs se font sur des float32.

        Parameters
        ----------
        theta_vect : np.ndarray
            * Vecteur des angles compris entre [-pi, pi].
            * shape = ``(*over_dims, nbr_inter)``
        dist_vect : np.ndarray
            * Vecteur des distances des droites a l&#39;origine comprises [0, +oo].
            * shape = ``(*over_dims, nbr_inter)``
        tol : float
            La distance maximal separant 2 points dans l&#39;espace de hough reduit,
            (ie la difference entre 2 droites dans l&#39;espace spacial) tel que les points
            se retrouvent dans le meme cluster. Plus ce nombre est petit, plus les points
            doivent etre bien alignes. C&#39;est une sorte de tolerance sur l&#39;alignement.
        nbr : int
            C&#39;est le nombre minimum de points presque alignes pour que
            l&#39;on puisse considerer la droite qui passe par ces points.
            Par defaut, les droites qui ne passent que par 4 points et plus sont retenues.

        Returns
        -------
        np.ndarray(dtype=float32), np.ndarray(dtype=object)
            * Ce sont les centres des clusters pour chaque &#39;nuages de points&#39;. Cela correspond
            aux angles et aux distances qui caracterisent chaque droites.
            * Si les parametres d&#39;entres sont des vecteurs 1d, le resultat sera une array
            numpy contenant les **angles** puis les **distances**. Donc de shape = ``(2, nbr_clusters)``
            * Si les parametres d&#39;entres sont en plusieur dimensions, (representes plusieur
            nuages de points indepandant), alors le resultat sera une array d&#39;objet de
            shape = ``(*over_dims)``. Chaque objet est lui meme un array, resultat recursif
            de l&#39;appel de cette fonction sur le nuage de points unique correspondant.

        Examples
        --------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue import geometry
        &gt;&gt;&gt; transformer = geometry.Transformer()

        Type de retour ``np.float32`` vs ``object``.
        &gt;&gt;&gt; x, y = (np.array([ 1.,  2.,  3.,  0., -1.]),
        ...         np.array([ 0.,  1.,  1., -1.,  1.]))
        &gt;&gt;&gt; theta, dist = transformer.hough(x, y)
        &gt;&gt;&gt; transformer.hough_reduce(theta, dist, nbr=3)
        array([[-0.7853982 ,  1.5707964 ],
               [ 0.70710677,  1.        ]], dtype=float32)
        &gt;&gt;&gt; transformer.hough_reduce(theta.reshape((1, -1)), dist.reshape((1, -1)), nbr=3)
        array([array([[-0.7853982 ,  1.5707964 ],
                      [ 0.70710677,  1.        ]], dtype=float32)], dtype=object)
        &gt;&gt;&gt;

        Les dimensions de retour.
        &gt;&gt;&gt; x, y = (np.random.normal(size=(6, 5, 4)),
        ...         np.random.normal(size=(6, 5, 4)))
        &gt;&gt;&gt; theta, dist = transformer.hough(x, y)
        &gt;&gt;&gt; transformer.hough_reduce(theta, dist).shape
        (6, 5)
        &gt;&gt;&gt; 
        &#34;&#34;&#34;
        assert isinstance(theta_vect, np.ndarray), \
            f&#34;&#39;theta_vect&#39; has to be of type np.ndarray, not {type(theta_vect).__name__}.&#34;
        assert isinstance(dist_vect, np.ndarray), \
            f&#34;&#39;dist_vect&#39; has to be of type np.ndarray, not {type(dist_vect).__name__}.&#34;
        assert theta_vect.shape == dist_vect.shape, \
            f&#34;Les 2 entrees doivent avoir la meme taille: {theta_vect.shape} vs {dist_vect.shape}.&#34;
        assert theta_vect.ndim &gt;= 1, &#34;La matrice ne doit pas etre vide.&#34;
        assert isinstance(tol, float), f&#34;&#39;tol&#39; has to be a float, not a {type(tol).__name__}.&#34;
        assert 0.0 &lt; tol &lt;= 0.5, (&#34;Les valeurs coherentes de &#39;tol&#39; se trouvent entre &#34;
            f&#34;]0, 1/2], or tol vaut {tol}, ce qui sort de cet intervalle.&#34;)
        assert isinstance(nbr, int), f&#34;&#39;nbr&#39; has to be an integer, not a {type(nbr).__name__}.&#34;
        assert 2 &lt; nbr, f&#34;2 points sont toujours alignes! Vous ne pouvez pas choisir nbr={nbr}.&#34;

        # On fait la conversion des le debut pour un gain de temps.
        theta_vect, dist_vect = theta_vect.astype(np.float32, copy=False), dist_vect.astype(np.float32, copy=False)

        *over_dims, nbr_inter = theta_vect.shape # Recuperation des dimensions.
        nbr = (nbr*(nbr-1))/2 # On converti le nombre de points alignes en nbr de segments.

        # On commence par travailler avec les donnees reduites.
        theta_theo_std = math.pi / math.sqrt(3) # Variance theorique = (math.pi - -math.pi)**2 / 12
        dist_std = np.nanstd(dist_vect, axis=-1) # Ecart type non biaise (sum(*over_dims)/N), shape: (*over_dims)
        dist_vect = (dist_vect * theta_theo_std
            / np.repeat(dist_std[..., np.newaxis], nbr_inter, axis=-1)) # Les distances quasi reduites.
        
        # Extraction des clusters.
        if not len(over_dims): # Cas des tableaux 1d.
            return self._clustering_1d(theta_vect, dist_vect, dist_std, tol, nbr)

        clusters = np.empty(np.prod(over_dims, dtype=int), dtype=object) # On doit d&#39;abord creer un tableau d&#39;objet 1d.
        if multiprocessing.current_process().name == &#34;MainProcess&#34; and np.prod(over_dims) &gt;= os.cpu_count(): # Si ca vaut le coup de parraleliser:
            ser_self = cloudpickle.dumps(self) # Strategie car &#39;pickle&#39; ne sais pas faire ca.
            from laue.tools.multi_core import pickleable_method
            with multiprocessing.Pool() as pool:
                clusters[:] = pool.map(
                    pickleable_method, # Car si il y a autant de cluster dans chaque image,
                    (                   # numpy aurait envi de faire un tableau 2d plutot qu&#39;un vecteur de listes.
                        (
                            Transformer._clustering_1d,
                            ser_self,
                            {&#34;theta_vect_1d&#34;:theta, &#34;dist_vect_1d&#34;:dist, &#34;std&#34;:std, &#34;tol&#34;:tol, &#34;nbr&#34;:nbr}
                        )
                        for theta, dist, std
                        in zip(
                            theta_vect.reshape((-1, nbr_inter)),
                            dist_vect.reshape((-1, nbr_inter)),
                            np.nditer(dist_std)
                        )
                    )
                )
        else:
            clusters[:] = [self._clustering_1d(theta, dist, std, tol, nbr)
                           for theta, dist, std in zip(
                                    theta_vect.reshape((-1, nbr_inter)),
                                    dist_vect.reshape((-1, nbr_inter)),
                                    np.nditer(dist_std))] 
        clusters = clusters.reshape(over_dims) # On redimensione a la fin de sorte a garentir les dimensions.

        return clusters

    def inter_lines(self, theta_vect, dist_vect):
        r&#34;&#34;&#34;
        ** Calcul les points d&#39;intersection entre les droites. **

        Notes
        -----
        * Cette methode est concue pour traiter les donnees issues de ``laue.geometry.Transformer.hough``.
        * En raison de performance et de memoire, les calculs se font sur des float32.
        * Les indices sont agences selon l&#39;ordre defini par la fonction ``comb2ind``.

        Parameters
        ----------
        theta_vect : np.ndarray
            * Vecteur des angles compris entre [-pi, pi].
            * shape = (*over_dims, nbr_droites)
        dist_vect : np.ndarray
            * Vecteur des distances des droites a l&#39;origine comprises [0, +oo].
            * shape = (*over_dims, nbr_droites)

        Returns
        -------
        np.ndarray(dtype=float32)
            * Dans le dommaine spatial et non pas le domaine de hough, cherche
            les intersections des droites. Il y a ``n*(n-1)/2`` intersections, n etant
            le nombre de droites. donc la complexite de cette methode est en ``o(n**2)``.
            * Si les vecteurs d&#39;entre sont des vecteurs 1d (ie ``*over_dims == ()``), 
            Seront retournes le vecteur d&#39;intersection selon l&#39;axe x et le vecteur
            des intersections selon l&#39;axe y. Ces 2 vecteurs de meme taille sont concatenes
            sous la forme d&#39;une matrice de shape = ``(2, n*(n-1)/2)``.
            * Si les vecteurs d&#39;entre sont en plusieurs dimensions, seul les droites de la
            derniere dimensions se retrouvent dans la meme famille. Tous comme pour les
            vecteurs 1d, on trouve d&#39;abord les intersections selon x puis en suite selon y.
            La shape du tenseur final est donc: ** shape = ``(2, *over_dims, n*(n-1)/2)`` **.

        Examples
        -------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue.geometry import Transformer
        &gt;&gt;&gt; transformer = Transformer()
        &gt;&gt;&gt; np.random.seed(0)
        &gt;&gt;&gt; x, y = np.random.normal(size=(2, 4, 5, 6))
        &gt;&gt;&gt; theta, dist = transformer.hough(x, y)
        &gt;&gt;&gt; theta.shape
        (4, 5, 15)
        &gt;&gt;&gt; transformer.inter_lines(theta, dist).shape
        (2, 4, 5, 105)
        &gt;&gt;&gt;
        &#34;&#34;&#34;
        assert isinstance(theta_vect, np.ndarray), \
            f&#34;&#39;theta_vect&#39; has to be of type np.ndarray, not {type(theta_vect).__name__}.&#34;
        assert isinstance(dist_vect, np.ndarray), \
            f&#34;&#39;dist_vect&#39; has to be of type np.ndarray, not {type(dist_vect).__name__}.&#34;
        assert theta_vect.shape == dist_vect.shape, \
            f&#34;Les 2 entrees doivent avoir la meme taille: {theta_vect.shape} vs {dist_vect.shape}.&#34;
        assert theta_vect.ndim &gt;= 1, &#34;La matrice ne doit pas etre vide.&#34;
        assert theta_vect.shape[-1] &gt;= 2, \
            f&#34;Il doit y avoir au moins 2 droites par famille, pas {theta_vect.shape[-1]}.&#34;

        theta_vect, dist_vect = theta_vect.astype(np.float32, copy=False), dist_vect.astype(np.float32, copy=False)
        n = theta_vect.shape[-1]

        theta_1 = np.concatenate([np.repeat(theta_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
        dist_1 = np.concatenate([np.repeat(dist_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
        theta_2 = np.concatenate([theta_vect[..., i+1:] for i in range(n-1)], axis=-1)
        dist_2 = np.concatenate([dist_vect[..., i+1:] for i in range(n-1)], axis=-1)

        return self.get_fct_inter_line()(theta_1, dist_1, theta_2, dist_2)

    def _clustering_1d(self, theta_vect_1d, dist_vect_1d, std, tol, nbr):
        &#34;&#34;&#34;
        ** Help for hough_reduce. **

        * Permet de trouver les clusters d&#39;un nuage de points.
        * La projection 3d, bien que moins realiste, est 20% plus rapide que la distance reele.
        &#34;&#34;&#34;
        from sklearn.cluster import DBSCAN

        THETA_STD = np.float32(math.pi / math.sqrt(3))
        WEIGHT = 0.65 # 0 =&gt; tres souple sur les angles, 1=&gt; tres souple sur les distances.

        # On retire les droites aberantes.
        mask_to_keep = np.isfinite(theta_vect_1d) &amp; np.isfinite(dist_vect_1d)
        if not mask_to_keep.any(): # Si il ne reste plus rien.
            return np.array([], dtype=np.float32)
        theta_vect_1d, dist_vect_1d = theta_vect_1d[mask_to_keep], dist_vect_1d[mask_to_keep]

        # On passe dans un autre repere de facon a ce que -pi et pi se retrouvent a cote.
        if numexpr is not None:
            theta_x = numexpr.evaluate(&#34;2*WEIGHT*cos(theta_vect_1d)&#34;)
            theta_y = numexpr.evaluate(&#34;2*WEIGHT*sin(theta_vect_1d)&#34;)
        else:
            theta_x, theta_y = 2*WEIGHT*np.cos(theta_vect_1d), 2*WEIGHT*np.sin(theta_vect_1d)

        # Recherche des clusters.
        n_jobs = -1 if multiprocessing.current_process().name == &#34;MainProcess&#34; else 1
        db_res = DBSCAN(eps=tol, min_samples=nbr, n_jobs=n_jobs).fit(
            np.vstack((theta_x, theta_y, 2*(1-WEIGHT)*dist_vect_1d)).transpose())

        # Mise en forme des clusters.
        clusters_dict = collections.defaultdict(lambda: [])
        keep = db_res.labels_ != -1 # Les indices des clusters a garder.
        for x_cyl, y_cyl, dist, group in zip(
                theta_x[keep], theta_y[keep], dist_vect_1d[keep], db_res.labels_[keep]):
            clusters_dict[group].append((x_cyl, y_cyl, dist))

        theta = np.array([np.arccos(cluster[:, 0].mean()/(2*WEIGHT))*np.sign(cluster[:, 1].sum())
                    for cluster in map(np.array, clusters_dict.values())],
                    dtype=np.float32)
        dist = np.array([cluster[:, 2].mean()
                        for cluster in map(np.array, clusters_dict.values())],
                    dtype=np.float32) * std / THETA_STD
        return np.array([theta, dist], dtype=np.float32)

    def _hash_parameters(self, parameters):
        &#34;&#34;&#34;
        ** Hache le dictionaire des parametres. **

        * Il n&#39;y a pas de verification pour des histoires de performances.

        Parameters
        ----------
        parameters : dict
            Dictionaire des parametres issues de ``laue.tools.parsing.extract_parameters``.

        Returns
        -------
        int
            Un identifiant tq 2 dictionaires identiques renvoient le meme id.
        &#34;&#34;&#34;
        return hash(( # Il faut imperativement garantir l&#39;ordre.
            parameters[&#34;dd&#34;],
            parameters[&#34;xcen&#34;],
            parameters[&#34;ycen&#34;],
            parameters[&#34;xbet&#34;],
            parameters[&#34;xgam&#34;],
            parameters[&#34;pixelsize&#34;]))


def comb2ind(ind1, ind2, n):
    &#34;&#34;&#34;
    ** Transforme 2 indices en un seul. **

    Note
    ----
    * Bijection de ``ind2comb``.
    * Peut etre utile pour les methodes ``laue.geometry.Transformer.hough``
    et ``laue.geometry.Transformer.inter_lines``.

    Parameters
    ----------
    ind1 : int ou np.ndarray(dtype=int)
        L&#39;indice du premier element: ``0 &lt;= ind1``.
    ind2 : int ou np.ndarray(dtype=int)
        L&#39;indice du second element: ``ind1 &lt; ind2``.
    n : int
        Le nombre de symboles : ``2 &lt;= n and ind2 &lt; n``.

    Returns
    -------
    int, np.ndarray(dtype=int)
        Le nombre de mots contenant exactement 2 symboles dans un
        alphabet de cardinal ``n``. Sachant que le deuxieme symbole
        est stricement superieur au premier, et que les mots sont
        generes avec le comptage naturel (representation des nombres
        en base n).

    Examples
    -------
    &gt;&gt;&gt; from laue.geometry import comb2ind
    &gt;&gt;&gt; comb2ind(0, 1, n=6)
    0
    &gt;&gt;&gt; comb2ind(0, 2, n=6)
    1
    &gt;&gt;&gt; comb2ind(0, 5, n=6)
    4
    &gt;&gt;&gt; comb2ind(1, 2, n=6)
    5
    &gt;&gt;&gt; comb2ind(4, 5, n=6)
    14
    &#34;&#34;&#34;
    assert isinstance(ind1, (int, np.ndarray)), \
        f&#34;&#39;ind1&#39; can not being of type {type(ind1).__name__}.&#34;
    assert isinstance(ind2, (int, np.ndarray)), \
        f&#34;&#39;ind2&#39; can not being of type {type(ind2).__name__}.&#34;
    assert isinstance(n, int), f&#34;&#39;n&#39; has to ba an integer, not a {type(n).__name__}.&#34;
    if isinstance(ind1, np.ndarray):
        assert ind1.dtype == int, f&#34;&#39;ind1&#39; must be integer, not {str(ind1.dtype)}.&#34;
        assert (ind1 &gt;= 0).all(), &#34;Tous les indices doivent etres positifs.&#34;
    else:
        assert ind1 &gt;= 0, &#34;Les indices doivent etre positifs.&#34;
    if isinstance(ind2, np.ndarray):
        assert ind2.dtype == int, f&#34;&#39;ind2&#39; must be integer, not {str(ind2.dtype)}.&#34;
        assert ind1.shape == ind2.shape, (&#34;Si les indices sont des arrays, elles doivent &#34;
            f&#34;toutes 2 avoir les memes dimensions. {ind1.shape} vs {ind2.shape}.&#34;)
        assert (ind2 &gt; ind1).all(), (&#34;Les 2ieme indices doivent &#34;
            &#34;etres strictement superieur aux premiers.&#34;)
        assert (ind2 &lt; n).all(), &#34;Vous aimez un peu trop les &#39;index out of range&#39;.&#34;
    else:
        assert ind2 &gt; ind1, (&#34;Le 2ieme indice doit etre strictement superieur au premier. &#34;
            f&#34;{ind1} vs {ind2}.&#34;)
        assert ind2 &lt; n, &#34;Vous aimez un peu trop les &#39;index out of range&#39;.&#34;

    return n*ind1 - (ind1**2 + 3*ind1)//2 + ind2 - 1

def ind2comb(comb, n):
    &#34;&#34;&#34;
    ** Eclate un rang en 2 indices **

    Notes
    -----
    * Bijection de ``comb2ind``.
    * Peut etre utile pour les methodes ``laue.geometry.Transformer.hough``
    et ``laue.geometry.Transformer.inter_lines``.
    * Risque de donner de faux resultats pour n trop grand.

    Parameters
    ----------
    comb : int ou np.ndarray(dtype=int)
        L&#39;indice, ie le (comb)ieme mot constitue 2 de symbols
        ajence comme decrit dans ``comb2ind``.
    n : int
        Le nombre de symboles.

    Returns
    -------
    int ou np.ndarray(dtype=int)
        Le premier des 2 indicices (``ind1``).
    int ou np.ndarray(dtype=int)
        Le second des 2 indicices (``ind2``). De sorte que ``comb2ind(ind1, ind2) == comb``.

    Examples
    --------
    &gt;&gt;&gt; from laue.geometry import ind2comb
    &gt;&gt;&gt; ind2comb(0, n=6)
    (0, 1)
    &gt;&gt;&gt; ind2comb(1, n=6)
    (0, 2)
    &gt;&gt;&gt; ind2comb(4, n=6)
    (0, 5)
    &gt;&gt;&gt; ind2comb(5, n=6)
    (1, 2)
    &gt;&gt;&gt; ind2comb(14, n=6)
    (4, 5)
    &gt;&gt;&gt;
    &#34;&#34;&#34;
    assert isinstance(comb, (int, np.ndarray)), \
        f&#34;&#39;comb&#39; can not being of type {type(comb).__name__}.&#34;
    assert isinstance(n, int), f&#34;&#39;n&#39; has to ba an integer, not a {type(n).__name__}.&#34;
    if isinstance(comb, np.ndarray):
        assert comb.dtype == int, f&#34;&#39;comb&#39; must be integer, not {str(comb.dtype)}.&#34;
        assert (comb &gt;= 0).all(), &#34;Tous les indices doivent etres positifs.&#34;
        assert (comb &lt; n*(n-1)/2).all(), (f&#34;Dans un alphabet a {n} symboles, il ne peut y a voir &#34;
            f&#34;que {n*(n-1)/2} mots. Le mot d&#39;indice {comb.max()} n&#39;existe donc pas!&#34;)
    else:
        assert comb &gt;= 0, &#34;Les indices doivent etre positifs.&#34;
        assert comb &lt; n*(n-1)/2, (f&#34;Dans un alphabet a {n} symboles, il ne peut y a voir &#34;
            f&#34;que {n*(n-1)/2} mots. Le mot d&#39;indice {comb} n&#39;existe donc pas!&#34;)

    homogeneous_int = lambda x: x.astype(int) if isinstance(x, np.ndarray) else int(x)
    ind1 = homogeneous_int(np.ceil(n - np.sqrt(-8*comb + 4*n**2 - 4*n - 7)/2 - 3/2))
    ind2 = comb + (ind1**2 + 3*ind1)//2 - ind1*n + 1
    return ind1, ind2


class _Lambdify:
    &#34;&#34;&#34;
    Vectorize une expression sympy.
    &#34;&#34;&#34;
    def __init__(self, args, expr, modules=None):
        &#34;&#34;&#34;
        Notes
        -----
        * Est plus efficace si le module ``numexpr`` est installe.
        * Force a convertir le type de retour en float.

        Parameters
        ----------
        :param parameters: Les parametres constant a remplacer.
        For all other parameters, they are exactly the same as  ``sympy.lambdify``.
        &#34;&#34;&#34;
        self.sub_var_cmp = 0 # Compteur qui permet de creer plein de variables sympy.

        self.args = args
        self.modules = modules
        self.expr = self._expr2sym(expr)
        self.operations = collections.OrderedDict() # Contient la suite d&#39;operations.
        self._gather(args, self.expr) # Remplissage des etapes de calcul.
        # self.operations[&#34;final_result&#34;] = (sympy.lambdify(args, self.expr), self.expr, [])

    def __call__(self, *args):
        &#34;&#34;&#34;
        Evalue la fonction.
        &#34;&#34;&#34;
        intermediate = collections.OrderedDict(zip(self.args, args)) # Ce sont les resultats intermediaires.
        for var, (func, _, useless_vars) in self.operations.items():
            intermediate[var] = func(*intermediate.values())
            for var_u in useless_vars:
                del intermediate[var_u]
        return np.real(intermediate[&#34;final_result&#34;])

    def __repr__(self):
        &#34;&#34;&#34;
        Donne une representation evaluable de soi.
        &#34;&#34;&#34;
        return f&#34;_Lambdify({self.args}, {self.expr})&#34;

    def __str__(self):
        &#34;&#34;&#34;
        Retourne le code deplie.
        &#34;&#34;&#34;
        code = f&#34;def _lambdifygenerated({&#39;, &#39;.join(map(str, self.args))}):\n&#34;
        for var, (_, expr, useless_vars) in self.operations.items():
            code += f&#34;\t{var} = {expr}\n&#34;
            if useless_vars:
                code += f&#34;\tdel {&#39;, &#39;.join(map(str, useless_vars))}\n&#34;
        code += &#34;\treturn final_result\n&#34;
        return code

    def get_expr(self):
        &#34;&#34;&#34;
        Recupere l&#39;expression brute sympy.

        :returns: L&#39;expression sympy liee au parametre &#39;expr&#39; de self.__init__.
        :rtype: sympy.core.basic.Basic
        &#34;&#34;&#34;
        return self.expr

    def _expr2sym(self, expr):
        &#34;&#34;&#34;
        Transforme &#39;expr&#39; en expression sympy.

        :param expr: Expression sympy, tuple, liste, str
        :returns: Une expression sympy complete.
        &#34;&#34;&#34;
        assert isinstance(expr, (sympy.core.basic.Basic, list, tuple, str)), \
            f&#34;&#39;expression&#39; has to be list, tuple or sympy expr, not {type(expression).__name__}.&#34;

        if isinstance(expr, sympy.core.basic.Basic):
            return expr

        if isinstance(expr, str):
            standard_transformations = sympy.parsing.sympy_parser.standard_transformations
            implicit_multiplication_application = sympy.parsing.sympy_parser.implicit_multiplication_application
            transformations = (standard_transformations + (implicit_multiplication_application,))
            return self._expr2sym(sympy.parse_expr(expr, transformations=transformations))

        return sympy.Tuple(*[self._expr2sym(child) for child in expr])

    def _gather(self, variables, expr):
        &#34;&#34;&#34;
        Supprime la redondance.
        &#34;&#34;&#34;
        if isinstance(expr, sympy.core.basic.Atom): # Si il n&#39;y a rien a symplifier.
            self.operations[&#34;final_result&#34;] = (sympy.lambdify(variables, expr), expr, [])
            return

        complete_hist = self._hist_sub_expr(expr) # Histograme complet des descendances.
        max_red = max(complete_hist.values()) # Redondance maximale.
        if max_red == 1: # Si il n&#39;y a pas de redondance.
            self.operations[&#34;final_result&#34;] = (sympy.lambdify(variables, expr), expr, [])
            return

        max_red_expr = [expr for expr, red in complete_hist.items() if red == max_red] # Seul les elements les plus redondants.

        dephs = [self._len(expr) for expr in max_red_expr] # 3 La profondeur respective de chaque arbre.
        sub_expr = max_red_expr[np.argmax(dephs)] # L&#39;expression de l&#39;element a remplacer.
        self.sub_var_cmp += 1 # On incremente le conteur pour creer une nouvelle variable unique.
        sub_var = sympy.Symbol(f&#34;subvar_{self.sub_var_cmp}&#34;) # Nom de la variable intermediaire.
        expr = expr.xreplace({sub_expr: sub_var})

        useless_vars = set(variables) - expr.free_symbols # Se sont les variables inutiles par la suite.
        try:
            self.operations[sub_var] = (sympy.lambdify(variables, sub_expr, modules=self.modules), sub_expr, useless_vars) # ajoute de l&#39;etape de calcul.
        except (ImportError, TypeError):
            self.operations[sub_var] = (sympy.lambdify(variables, sub_expr), sub_expr, useless_vars)
        variables = [var for var in variables if var not in useless_vars] # On vire les variables inutiles.

        return self._gather(variables+[sub_var], expr) # On simplifie, puis on recommence.

    def _hist_sub_expr(self, expr):
        &#34;&#34;&#34;
        Fait l&#39;histograme des enfants.

        * Ne fait pas de verification pour plus de permormances.
        * Ne compte pas les symbols et les nombres.

        :param expr: Expression sympy derivee de sympy.core.basic.Basic
        :returns: Le dictionaire qui a chaque enfant et descendant en general,
            associ son nombre d&#39;apparition.
        &#34;&#34;&#34;
        hist = collections.defaultdict(lambda: 0)
        for child in expr.args:
            if child.is_number or child.is_symbol:
                continue
            hist[child] += 1
            for little_child, occur in self._hist_sub_expr(child).items():
                hist[little_child] += occur
        return hist

    def _len(self, expr):
        &#34;&#34;&#34;
        Cherche le nombres d&#39;elements.

        * Pas de verification pour une question de performance
        &#34;&#34;&#34;
        return 1 + sum(self._len(child) for child in expr.args)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="laue.geometry.comb2ind"><code class="name flex">
<span>def <span class="ident">comb2ind</span></span>(<span>ind1, ind2, n)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Transforme 2 indices en un seul. </strong></p>
<h2 id="note">Note</h2>
<ul>
<li>Bijection de <code><a title="laue.geometry.ind2comb" href="#laue.geometry.ind2comb">ind2comb()</a></code>.</li>
<li>Peut etre utile pour les methodes <code><a title="laue.geometry.Transformer.hough" href="#laue.geometry.Transformer.hough">Transformer.hough()</a></code>
et <code><a title="laue.geometry.Transformer.inter_lines" href="#laue.geometry.Transformer.inter_lines">Transformer.inter_lines()</a></code>.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ind1</code></strong> :&ensp;<code>int ou np.ndarray(dtype=int)</code></dt>
<dd>L'indice du premier element: <code>0 &lt;= ind1</code>.</dd>
<dt><strong><code>ind2</code></strong> :&ensp;<code>int ou np.ndarray(dtype=int)</code></dt>
<dd>L'indice du second element: <code>ind1 &lt; ind2</code>.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Le nombre de symboles : <code>2 &lt;= n and ind2 &lt; n</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int, np.ndarray(dtype=int)</code></dt>
<dd>Le nombre de mots contenant exactement 2 symboles dans un
alphabet de cardinal <code>n</code>. Sachant que le deuxieme symbole
est stricement superieur au premier, et que les mots sont
generes avec le comptage naturel (representation des nombres
en base n).</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from laue.geometry import comb2ind
&gt;&gt;&gt; comb2ind(0, 1, n=6)
0
&gt;&gt;&gt; comb2ind(0, 2, n=6)
1
&gt;&gt;&gt; comb2ind(0, 5, n=6)
4
&gt;&gt;&gt; comb2ind(1, 2, n=6)
5
&gt;&gt;&gt; comb2ind(4, 5, n=6)
14
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def comb2ind(ind1, ind2, n):
    &#34;&#34;&#34;
    ** Transforme 2 indices en un seul. **

    Note
    ----
    * Bijection de ``ind2comb``.
    * Peut etre utile pour les methodes ``laue.geometry.Transformer.hough``
    et ``laue.geometry.Transformer.inter_lines``.

    Parameters
    ----------
    ind1 : int ou np.ndarray(dtype=int)
        L&#39;indice du premier element: ``0 &lt;= ind1``.
    ind2 : int ou np.ndarray(dtype=int)
        L&#39;indice du second element: ``ind1 &lt; ind2``.
    n : int
        Le nombre de symboles : ``2 &lt;= n and ind2 &lt; n``.

    Returns
    -------
    int, np.ndarray(dtype=int)
        Le nombre de mots contenant exactement 2 symboles dans un
        alphabet de cardinal ``n``. Sachant que le deuxieme symbole
        est stricement superieur au premier, et que les mots sont
        generes avec le comptage naturel (representation des nombres
        en base n).

    Examples
    -------
    &gt;&gt;&gt; from laue.geometry import comb2ind
    &gt;&gt;&gt; comb2ind(0, 1, n=6)
    0
    &gt;&gt;&gt; comb2ind(0, 2, n=6)
    1
    &gt;&gt;&gt; comb2ind(0, 5, n=6)
    4
    &gt;&gt;&gt; comb2ind(1, 2, n=6)
    5
    &gt;&gt;&gt; comb2ind(4, 5, n=6)
    14
    &#34;&#34;&#34;
    assert isinstance(ind1, (int, np.ndarray)), \
        f&#34;&#39;ind1&#39; can not being of type {type(ind1).__name__}.&#34;
    assert isinstance(ind2, (int, np.ndarray)), \
        f&#34;&#39;ind2&#39; can not being of type {type(ind2).__name__}.&#34;
    assert isinstance(n, int), f&#34;&#39;n&#39; has to ba an integer, not a {type(n).__name__}.&#34;
    if isinstance(ind1, np.ndarray):
        assert ind1.dtype == int, f&#34;&#39;ind1&#39; must be integer, not {str(ind1.dtype)}.&#34;
        assert (ind1 &gt;= 0).all(), &#34;Tous les indices doivent etres positifs.&#34;
    else:
        assert ind1 &gt;= 0, &#34;Les indices doivent etre positifs.&#34;
    if isinstance(ind2, np.ndarray):
        assert ind2.dtype == int, f&#34;&#39;ind2&#39; must be integer, not {str(ind2.dtype)}.&#34;
        assert ind1.shape == ind2.shape, (&#34;Si les indices sont des arrays, elles doivent &#34;
            f&#34;toutes 2 avoir les memes dimensions. {ind1.shape} vs {ind2.shape}.&#34;)
        assert (ind2 &gt; ind1).all(), (&#34;Les 2ieme indices doivent &#34;
            &#34;etres strictement superieur aux premiers.&#34;)
        assert (ind2 &lt; n).all(), &#34;Vous aimez un peu trop les &#39;index out of range&#39;.&#34;
    else:
        assert ind2 &gt; ind1, (&#34;Le 2ieme indice doit etre strictement superieur au premier. &#34;
            f&#34;{ind1} vs {ind2}.&#34;)
        assert ind2 &lt; n, &#34;Vous aimez un peu trop les &#39;index out of range&#39;.&#34;

    return n*ind1 - (ind1**2 + 3*ind1)//2 + ind2 - 1</code></pre>
</details>
</dd>
<dt id="laue.geometry.ind2comb"><code class="name flex">
<span>def <span class="ident">ind2comb</span></span>(<span>comb, n)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Eclate un rang en 2 indices </strong></p>
<h2 id="notes">Notes</h2>
<ul>
<li>Bijection de <code><a title="laue.geometry.comb2ind" href="#laue.geometry.comb2ind">comb2ind()</a></code>.</li>
<li>Peut etre utile pour les methodes <code><a title="laue.geometry.Transformer.hough" href="#laue.geometry.Transformer.hough">Transformer.hough()</a></code>
et <code><a title="laue.geometry.Transformer.inter_lines" href="#laue.geometry.Transformer.inter_lines">Transformer.inter_lines()</a></code>.</li>
<li>Risque de donner de faux resultats pour n trop grand.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>comb</code></strong> :&ensp;<code>int ou np.ndarray(dtype=int)</code></dt>
<dd>L'indice, ie le (comb)ieme mot constitue 2 de symbols
ajence comme decrit dans <code><a title="laue.geometry.comb2ind" href="#laue.geometry.comb2ind">comb2ind()</a></code>.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Le nombre de symboles.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int ou np.ndarray(dtype=int)</code></dt>
<dd>Le premier des 2 indicices (<code>ind1</code>).</dd>
<dt><code>int ou np.ndarray(dtype=int)</code></dt>
<dd>Le second des 2 indicices (<code>ind2</code>). De sorte que <code>comb2ind(ind1, ind2) == comb</code>.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from laue.geometry import ind2comb
&gt;&gt;&gt; ind2comb(0, n=6)
(0, 1)
&gt;&gt;&gt; ind2comb(1, n=6)
(0, 2)
&gt;&gt;&gt; ind2comb(4, n=6)
(0, 5)
&gt;&gt;&gt; ind2comb(5, n=6)
(1, 2)
&gt;&gt;&gt; ind2comb(14, n=6)
(4, 5)
&gt;&gt;&gt;
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ind2comb(comb, n):
    &#34;&#34;&#34;
    ** Eclate un rang en 2 indices **

    Notes
    -----
    * Bijection de ``comb2ind``.
    * Peut etre utile pour les methodes ``laue.geometry.Transformer.hough``
    et ``laue.geometry.Transformer.inter_lines``.
    * Risque de donner de faux resultats pour n trop grand.

    Parameters
    ----------
    comb : int ou np.ndarray(dtype=int)
        L&#39;indice, ie le (comb)ieme mot constitue 2 de symbols
        ajence comme decrit dans ``comb2ind``.
    n : int
        Le nombre de symboles.

    Returns
    -------
    int ou np.ndarray(dtype=int)
        Le premier des 2 indicices (``ind1``).
    int ou np.ndarray(dtype=int)
        Le second des 2 indicices (``ind2``). De sorte que ``comb2ind(ind1, ind2) == comb``.

    Examples
    --------
    &gt;&gt;&gt; from laue.geometry import ind2comb
    &gt;&gt;&gt; ind2comb(0, n=6)
    (0, 1)
    &gt;&gt;&gt; ind2comb(1, n=6)
    (0, 2)
    &gt;&gt;&gt; ind2comb(4, n=6)
    (0, 5)
    &gt;&gt;&gt; ind2comb(5, n=6)
    (1, 2)
    &gt;&gt;&gt; ind2comb(14, n=6)
    (4, 5)
    &gt;&gt;&gt;
    &#34;&#34;&#34;
    assert isinstance(comb, (int, np.ndarray)), \
        f&#34;&#39;comb&#39; can not being of type {type(comb).__name__}.&#34;
    assert isinstance(n, int), f&#34;&#39;n&#39; has to ba an integer, not a {type(n).__name__}.&#34;
    if isinstance(comb, np.ndarray):
        assert comb.dtype == int, f&#34;&#39;comb&#39; must be integer, not {str(comb.dtype)}.&#34;
        assert (comb &gt;= 0).all(), &#34;Tous les indices doivent etres positifs.&#34;
        assert (comb &lt; n*(n-1)/2).all(), (f&#34;Dans un alphabet a {n} symboles, il ne peut y a voir &#34;
            f&#34;que {n*(n-1)/2} mots. Le mot d&#39;indice {comb.max()} n&#39;existe donc pas!&#34;)
    else:
        assert comb &gt;= 0, &#34;Les indices doivent etre positifs.&#34;
        assert comb &lt; n*(n-1)/2, (f&#34;Dans un alphabet a {n} symboles, il ne peut y a voir &#34;
            f&#34;que {n*(n-1)/2} mots. Le mot d&#39;indice {comb} n&#39;existe donc pas!&#34;)

    homogeneous_int = lambda x: x.astype(int) if isinstance(x, np.ndarray) else int(x)
    ind1 = homogeneous_int(np.ceil(n - np.sqrt(-8*comb + 4*n**2 - 4*n - 7)/2 - 3/2))
    ind2 = comb + (ind1**2 + 3*ind1)//2 - ind1*n + 1
    return ind1, ind2</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="laue.geometry.Transformer"><code class="flex name class">
<span>class <span class="ident">Transformer</span></span>
</code></dt>
<dd>
<div class="desc"><p>Permet d'effectuer des transformations geometrique comme jongler
entre l'espace de la camera et l'espace gnomonique ou encore
s'ammuser avec la transformee de Hough.</p>
<p>Genere le dictionaire a protee globale.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Transformer(Compilator):
    &#34;&#34;&#34;
    Permet d&#39;effectuer des transformations geometrique comme jongler
    entre l&#39;espace de la camera et l&#39;espace gnomonique ou encore
    s&#39;ammuser avec la transformee de Hough.
    &#34;&#34;&#34;
    def __init__(self):
        # Les constantes.
        self.dd = sympy.Symbol(&#34;dd&#34;, real=True, positive=True) # Distance entre l&#39;origine et le plan de la camera en mm.
        self.xcen, self.ycen = sympy.symbols(&#34;xcen ycen&#34;, real=True) # Position du point d&#39;incidence normale en pxl par rapport au repere de la camera.
        self.xbet, self.xgam = sympy.symbols(&#34;beta gamma&#34;, real=True) # Rotation autour x camera, Rotation autour axe incidence normale.
        self.pixelsize = sympy.Symbol(&#34;alpha&#34;, real=True, positive=True) # Taille des pixels en mm/pxl.

        # Les variables.
        self.x_cam, self.y_cam = sympy.symbols(&#34;x_cam y_cam&#34;, real=True, positive=True) # Position du pxl dans le repere du plan de la camera.
        self.x_gnom, self.y_gnom = sympy.symbols(&#34;x_gnom y_gnom&#34;, real=True) # Position des points dans le plan gnomonic.
        self.theta, self.chi = sympy.symbols(&#34;theta chi&#34;, real=True) # Les angles decrivant le rayon reflechit.

        # Expression des elements du model.
        self.rx = sympy.Matrix([1, 0, 0])
        self.ry = sympy.Matrix([0, 1, 0])
        self.rz = sympy.Matrix([0, 0, 1])

        self.u_i = self.rx # Le rayon de lumiere incident norme parallele a l&#39;axe X dans le repere du cristal.

        self.rot_camera = sympy.rot_axis2(-self.xbet) @ sympy.rot_axis3(self.xgam) # Rotation globale de la camera par rapport au cristal.
        self.ci = self.rot_camera @ -self.ry # Vecteur Xcamera.
        self.cj = self.rot_camera @ self.rx # Vecteur Ycamera.
        self.ck = self.rot_camera @ self.rz # Vecteur Zcamera normal au plan de la camera.

        self.rot_gnom = sympy.rot_axis2(-sympy.pi/4) # Rotation du repere de plan gnomonic par rapport au repere du cristal.
        self.gi = self.rot_gnom @ self.rz # Vecteur Xgnomonic.
        self.gj = self.rot_gnom @ self.ry # Vecteur Ygnomonic.
        self.gk = self.rot_gnom @ -self.rx # Vecteur Zgnomonic normal au plan gnomonic.

        Compilator.__init__(self) # Globalisation des expressions.

        # Les memoires tampon.
        self._fcts_cam_to_gnomonic = collections.defaultdict(lambda: 0) # Fonctions vectorisees avec seulement f(x_cam, y_cam), les parametres sont deja remplaces.
        self._fcts_gnomonic_to_cam = collections.defaultdict(lambda: 0) # Fonctions vectorisees avec seulement f(x_gnom, y_gnom), les parametres sont deja remplaces.
        self._parameters_memory = {} # Permet d&#39;eviter de relire le dictionaire des parametres a chaque fois.

    def cam_to_gnomonic(self, pxl_x, pxl_y, parameters):
        &#34;&#34;&#34;
        ** Passe des points de la camera dans un plan gnomonic. **

        Notes
        -----
        * Les calculs sont effectues avec des float32 pour des histoire de performance.
        * Cette methode va 1.8 a 3.3 fois plus vite que celle de LaueTools.
        * Contrairement a LaueTools, cette methode prend en charge les vecteurs a n dimenssions.

        Parameters
        ----------
        pxl_x : float, int ou np.ndarray
            Coordonnee.s du.des pxl.s selon l&#39;axe x dans le repere de la camera. (en pxl)
        pxl_y : float, int ou np.ndarray
            Coordonnee.s du.des pxl.s selon l&#39;axe y dans le repere de la camera. (en pxl)
        parameters : dict
            Le dictionaire issue de la fonction ``laue.tools.parsing.extract_parameters``.

        Returns
        -------
        float ou np.ndarray
            Le.s coordonnee.s x puis y du.des point.s dans le plan gnomonic eprimee.s en mm.
            Les dimenssions du tableau de sortie sont les memes que celle du tableau d&#39;entree.
            shape de sortie = (2, *shape_d_entree)

        Examples
        -------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue.geometry import Transformer
        &gt;&gt;&gt; from laue.tools.parsing import extract_parameters
        &gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
        &gt;&gt;&gt; transformer = Transformer()
        &gt;&gt;&gt; x_cam, y_cam = np.linspace(0, 2048, 5), np.linspace(0, 2048, 5)
        &gt;&gt;&gt;
        &gt;&gt;&gt; transformer.cam_to_gnomonic(x_cam, y_cam, parameters).astype(np.float16)
        array([[-0.5127, -0.3064,  0.    ,  0.1676,  0.1342],
               [ 0.4033,  0.287 , -0.    , -0.4832, -0.9385]], dtype=float16)
        &gt;&gt;&gt;
        &#34;&#34;&#34;
        assert isinstance(pxl_x, (float, int, np.ndarray)), \
            f&#34;&#39;pxl_x&#39; can not be of type {type(pxl_x).__name__}.&#34;
        assert isinstance(pxl_y, (float, int, np.ndarray)), \
            f&#34;&#39;pxl_y&#39; can not be of type {type(pxl_y).__name__}.&#34;
        assert type(pxl_x) == type(pxl_y), \
            f&#34;Les 2 types sont differents: {type(pxl_x).__name__} vs {type(pxl_y).__name__}.&#34;
        if isinstance(pxl_x, np.ndarray):
            assert pxl_x.shape == pxl_y.shape, \
                f&#34;Ils n&#39;ont pas le meme taille: {pxl_x.shape} vs {pxl_y.shape}.&#34;
        assert isinstance(parameters, dict), (&#34;Les parametres doivent founis &#34;
            f&#34;dans un dictionaire, pas dans un {type(parameters).__name__}&#34;)
        assert set(parameters) == {&#34;dd&#34;, &#34;xbet&#34;, &#34;xgam&#34;, &#34;xcen&#34;, &#34;ycen&#34;, &#34;pixelsize&#34;}, \
            (&#34;Les clefs doivent etres &#39;dd&#39;, &#39;xbet&#39;, &#39;xgam&#39;, &#39;xcen&#39;, &#39;ycen&#39; et &#39;pixelsize&#39;. &#34;
            f&#34;Or les clefs sont {set(parameters)}.&#34;)
        assert all(isinstance(v, (float, int)) for v in parameters.values()), \
            &#34;La valeurs des parametres doivent toutes etre des nombres.&#34;

        if isinstance(pxl_x, np.ndarray):
            pxl_x, pxl_y = pxl_x.astype(np.float32, copy=False), pxl_y.astype(np.float32, copy=False)
        else:
            pxl_x, pxl_y = np.float32(pxl_x), np.float32(pxl_y)

        hash_param = self._hash_parameters(parameters) # Recuperation de la &#39;signature&#39; des parametres.
        optimized_func = self._fcts_cam_to_gnomonic[hash_param] # On regarde si il y a une fonction deja optimisee.

        if isinstance(optimized_func, int): # Si il n&#39;y a pas de fonction optimisee.
            nbr_access = optimized_func # Ce qui est enregistre et le nombre de fois que l&#39;on a chercher a y acceder.
            self._fcts_cam_to_gnomonic[hash_param] += 1 # Comme on cherche a y acceder actuelement, on peut incrementer le compteur.
            if nbr_access + 1 == 4: # Si c&#39;est la 4 eme fois qu&#39;on accede a la fonction.
                self.compile(parameters) # On optimise la fonction.
            else: # Si ce n&#39;est pas encore le moment de perdre du temps a optimiser.
                return self.get_expr_cam_to_gnomonic()(pxl_x, pxl_y,
                    parameters[&#34;dd&#34;], parameters[&#34;xcen&#34;], parameters[&#34;ycen&#34;],
                    parameters[&#34;xbet&#34;], parameters[&#34;xgam&#34;], parameters[&#34;pixelsize&#34;])

        return self._fcts_cam_to_gnomonic[hash_param](pxl_x, pxl_y)

    def dist_line(self, theta_vect, dist_vect, x_vect, y_vect):
        &#34;&#34;&#34;
        ** Calcul les distances projetees des points sur une droite. **

        Notes
        -----
        Pour des raisons de performances, travail avec des float32.

        Parameters
        ----------
        theta_vect : np.ndarray
            Les angles des droites normales aux droites principales.
            shape = ``(*nbr_droites)``
        dist_vect : np.ndarray
            Les distances entre les droites et l&#39;origine.
            shape = ``(*nbr_droites)``
        x_vect : np.ndarray
            L&#39;ensemble des coordonnees x des points.
            shape = ``(*nbr_points)``
        y_vect : np.ndarray
            L&#39;ensemble des coordonnees y des points.
            shape = ``(*nbr_points)``

        Returns
        -------
        np.ndarray
            Les distances des projetees des points sur chacunes des droites.
            shape = ``(*nbr_droites, *nbr_points)``

        Examples
        --------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue.geometry import Transformer
        &gt;&gt;&gt; from laue.tools.parsing import extract_parameters
        &gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
        &gt;&gt;&gt; transformer = Transformer()
        &gt;&gt;&gt;
        &gt;&gt;&gt; lines = (np.array([0, np.pi/2]), np.array([1, 1])) # Horizontale et verticale passant par (1, 1)
        &gt;&gt;&gt; points = (np.array([0, 1, 3, 0]), np.array([0, 1, 3, 1]))
        &gt;&gt;&gt; np.round(transformer.dist_line(*lines, *points))
        array([[1., 0., 2., 1.],
               [1., 0., 2., 0.]], dtype=float32)
        &gt;&gt;&gt;
        &#34;&#34;&#34;
        assert isinstance(theta_vect, np.ndarray), \
            f&#34;&#39;theta_vect&#39; has to be of type np.ndarray, not {type(theta_vect).__name__}.&#34;
        assert isinstance(dist_vect, np.ndarray), \
            f&#34;&#39;dist_vect&#39; has to be of type np.ndarray, not {type(dist_vect).__name__}.&#34;
        assert theta_vect.shape == dist_vect.shape, \
            f&#34;Les 2 parametres de droite doivent avoir la meme taille: {theta_vect.shape} vs {dist_vect.shape}.&#34;
        assert isinstance(x_vect, np.ndarray), \
            f&#34;&#39;x_vect&#39; has to be of type np.ndarray, not {type(x_vect).__name__}.&#34;
        assert isinstance(y_vect, np.ndarray), \
            f&#34;&#39;y_vect&#39; has to be of type np.ndarray, not {type(y_vect).__name__}.&#34;
        assert x_vect.shape == y_vect.shape, \
            f&#34;Les 2 coordonnees des points doivent avoir la meme shape: {x_vect.shape} vs {y_vect.shape}.&#34;

        theta_vect, dist_vect = theta_vect.astype(np.float32, copy=False), dist_vect.astype(np.float32, copy=False)
        x_vect, y_vect = x_vect.astype(np.float32, copy=False), y_vect.astype(np.float32, copy=False)

        nbr_droites = theta_vect.shape
        nbr_points = x_vect.shape

        # Ca ne vaut pas le coup de paralleliser car c&#39;est tres rapide.
        func = self.get_fct_dist_line()
        result = np.array([func(theta, dist, x_vect, y_vect)
                           for theta, dist
                           in zip(theta_vect.ravel(), dist_vect.ravel())
                          ], dtype=np.float32).reshape((*nbr_droites, *nbr_points))
        return result

    def gnomonic_to_cam(self, gnom_x, gnom_y, parameters):
        &#34;&#34;&#34;
        ** Passe des points du plan gnomonic vers la camera. **

        Parameters
        ----------
        gnom_x : float ou np.ndarray
            Coordonnee.s du.des point.s selon l&#39;axe x du repere du plan gnomonic. (en mm)
        gnom_y : float ou np.ndarray
            Coordonnee.s du.des point.s selon l&#39;axe y du repere du plan gnomonic. (en mm)
        parameters : dict
            Le dictionaire issue de la fonction ``laue.tools.parsing.extract_parameters``.

        Returns
        -------
        coords : np.ndarray
            * Le.s coordonnee.s x puis y du.des point.s dans le plan de la camera. (en pxl)
            * shape = (2, ...)

        Examples
        -------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue.geometry import Transformer
        &gt;&gt;&gt; from laue.tools.parsing import extract_parameters
        &gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
        &gt;&gt;&gt; transformer = Transformer()
        &gt;&gt;&gt; gnom_x, gnom_y = np.random.normal(size=(2, 10, 4))
        &gt;&gt;&gt;
        &gt;&gt;&gt; transformer.gnomonic_to_cam(gnom_x, gnom_y, parameters).shape
        (2, 10, 4)
        &gt;&gt;&gt; transformer.gnomonic_to_cam(.0, .0, parameters)
        array([1024., 1024.])
        &gt;&gt;&gt;
        &#34;&#34;&#34;
        assert isinstance(gnom_x, (float, int, np.ndarray)), \
            f&#34;&#39;gnom_x&#39; can not be of type {type(gnom_x).__name__}.&#34;
        assert isinstance(gnom_y, (float, int, np.ndarray)), \
            f&#34;&#39;gnom_y&#39; can not be of type {type(gnom_y).__name__}.&#34;
        assert type(gnom_x) == type(gnom_y), \
            f&#34;Les 2 types sont differents: {type(gnom_x).__name__} vs {type(gnom_y).__name__}.&#34;
        if isinstance(gnom_x, np.ndarray):
            assert gnom_x.shape == gnom_y.shape, \
                f&#34;Ils n&#39;ont pas la meme taille: {gnom_x.shape} vs {gnom_y.shape}.&#34;
        assert isinstance(parameters, dict), (&#34;Les parametres doivent founis &#34;
            f&#34;dans un dictionaire, pas dans un {type(parameters).__name__}&#34;)
        assert set(parameters) == {&#34;dd&#34;, &#34;xbet&#34;, &#34;xgam&#34;, &#34;xcen&#34;, &#34;ycen&#34;, &#34;pixelsize&#34;}, \
            (&#34;Les clefs doivent etres &#39;dd&#39;, &#39;xbet&#39;, &#39;xgam&#39;, &#39;xcen&#39;, &#39;ycen&#39; et &#39;pixelsize&#39;. &#34;
            f&#34;Or les clefs sont {set(parameters)}.&#34;)
        assert all(isinstance(v, (float, int)) for v in parameters.values()), \
            &#34;La valeurs des parametres doivent toutes etre des nombres.&#34;

        if isinstance(gnom_x, np.ndarray):
            gnom_x, gnom_y = gnom_x.astype(np.float32, copy=False), gnom_y.astype(np.float32, copy=False)
        else:
            gnom_x, gnom_y = np.float32(gnom_x), np.float32(gnom_y)

        hash_param = self._hash_parameters(parameters) # Recuperation de la &#39;signature&#39; des parametres.
        optimized_func = self._fcts_gnomonic_to_cam[hash_param] # On regarde si il y a une fonction deja optimisee.

        if isinstance(optimized_func, int): # Si il n&#39;y a pas de fonction optimisee.
            nbr_access = optimized_func # Ce qui est enregistre et le nombre de fois que l&#39;on a chercher a y acceder.
            self._fcts_gnomonic_to_cam[hash_param] += 1 # Comme on cherche a y acceder actuelement, on peut incrementer le compteur.
            if nbr_access + 1 == 4: # Si c&#39;est la 4 eme fois qu&#39;on accede a la fonction.
                self.compile(parameters) # On optimise la fonction.
            else: # Si ce n&#39;est pas encore le moment de perdre du temps a optimiser.
                return self.get_expr_gnomonic_to_cam()(gnom_x, gnom_y,
                    parameters[&#34;dd&#34;], parameters[&#34;xcen&#34;], parameters[&#34;ycen&#34;],
                    parameters[&#34;xbet&#34;], parameters[&#34;xgam&#34;], parameters[&#34;pixelsize&#34;])

        return self._fcts_gnomonic_to_cam[hash_param](gnom_x, gnom_y)

    def hough(self, x_vect, y_vect):
        r&#34;&#34;&#34;
        ** Transformee de hough avec des droites. **

        Note
        ----
        * Pour des raisons de performances, les calculs se font sur des float32.
        * Les indices sont agences selon l&#39;ordre defini par la fonction ``comb2ind``.

        Parameters
        ----------
        x_vect : np.ndarray
            L&#39;ensemble des coordonnees x des points de shape: (*over_dims, nbr_points)
        y_vect : np.ndarray
            L&#39;ensemble des coordonnees y des points de shape: (*over_dims, nbr_points)

        Returns
        -------
        theta : np.ndarray
            * Les angles au sens trigomometrique des vecteurs reliant l&#39;origine
            ``O`` (0, 0) au point ``P`` appartenant a la droite tel que ``||OP||``
            soit la plus petite possible.
            * theta € [-pi, pi]
            * shape = ``(*over_dims, n*(n-1)/2)``
        dist : np.ndarray
            * Ce sont les normes des vecteur ``OP``.
            * dist € [0, +oo].
            * shape = ``(*over_dims, n*(n-1)/2)``
        * Ces 2 grandeurs sont concatenees dans une seule array de
        shape = ``(2, *over_dims, n*(n-1)/2)``

        Examples
        --------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue import geometry
        &gt;&gt;&gt; transformer = geometry.Transformer()
        &gt;&gt;&gt; x, y = np.random.normal(size=(2, 6))
        &gt;&gt;&gt; transformer.hough(x, y).shape
        (2, 15)
        &gt;&gt;&gt;
        &gt;&gt;&gt; x, y = np.random.normal(size=(2, 4, 5, 6))
        &gt;&gt;&gt; transformer.hough(x, y).shape
        (2, 4, 5, 15)
        &gt;&gt;&gt; 
        &#34;&#34;&#34;
        assert isinstance(x_vect, np.ndarray), \
            f&#34;&#39;x_vect&#39; has to be of type np.ndarray, not {type(x_vect).__name__}.&#34;
        assert isinstance(y_vect, np.ndarray), \
            f&#34;&#39;y_vect&#39; has to be of type np.ndarray, not {type(y_vect).__name__}.&#34;
        assert x_vect.shape == y_vect.shape, \
            f&#34;Les 2 entrees doivent avoir la meme taille: {x_vect.shape} vs {y_vect.shape}.&#34;

        n = x_vect.shape[-1]
        x_vect, y_vect = x_vect.astype(np.float32, copy=False), y_vect.astype(np.float32, copy=False)

        xa = np.concatenate([np.repeat(x_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
        ya = np.concatenate([np.repeat(y_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
        xb = np.concatenate([x_vect[..., i+1:] for i in range(n-1)], axis=-1)
        yb = np.concatenate([y_vect[..., i+1:] for i in range(n-1)], axis=-1)

        return np.nan_to_num(
            self.get_fct_hough()(xa, ya, xb, yb),
            copy=False,
            nan=0.0)

    def hough_reduce(self, theta_vect, dist_vect, *, nbr=4, tol=0.018):
        &#34;&#34;&#34;
        ** Regroupe des droites ressemblantes. **

        Notes
        -----
        * Cette methode est concue pour traiter les donnees issues de ``laue.geometry.Transformer.hough``.
        * La metrique utilise est la distance euclidiene sur un cylindre ferme sur theta.
        * En raison de performance et de memoire, les calculs se font sur des float32.

        Parameters
        ----------
        theta_vect : np.ndarray
            * Vecteur des angles compris entre [-pi, pi].
            * shape = ``(*over_dims, nbr_inter)``
        dist_vect : np.ndarray
            * Vecteur des distances des droites a l&#39;origine comprises [0, +oo].
            * shape = ``(*over_dims, nbr_inter)``
        tol : float
            La distance maximal separant 2 points dans l&#39;espace de hough reduit,
            (ie la difference entre 2 droites dans l&#39;espace spacial) tel que les points
            se retrouvent dans le meme cluster. Plus ce nombre est petit, plus les points
            doivent etre bien alignes. C&#39;est une sorte de tolerance sur l&#39;alignement.
        nbr : int
            C&#39;est le nombre minimum de points presque alignes pour que
            l&#39;on puisse considerer la droite qui passe par ces points.
            Par defaut, les droites qui ne passent que par 4 points et plus sont retenues.

        Returns
        -------
        np.ndarray(dtype=float32), np.ndarray(dtype=object)
            * Ce sont les centres des clusters pour chaque &#39;nuages de points&#39;. Cela correspond
            aux angles et aux distances qui caracterisent chaque droites.
            * Si les parametres d&#39;entres sont des vecteurs 1d, le resultat sera une array
            numpy contenant les **angles** puis les **distances**. Donc de shape = ``(2, nbr_clusters)``
            * Si les parametres d&#39;entres sont en plusieur dimensions, (representes plusieur
            nuages de points indepandant), alors le resultat sera une array d&#39;objet de
            shape = ``(*over_dims)``. Chaque objet est lui meme un array, resultat recursif
            de l&#39;appel de cette fonction sur le nuage de points unique correspondant.

        Examples
        --------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue import geometry
        &gt;&gt;&gt; transformer = geometry.Transformer()

        Type de retour ``np.float32`` vs ``object``.
        &gt;&gt;&gt; x, y = (np.array([ 1.,  2.,  3.,  0., -1.]),
        ...         np.array([ 0.,  1.,  1., -1.,  1.]))
        &gt;&gt;&gt; theta, dist = transformer.hough(x, y)
        &gt;&gt;&gt; transformer.hough_reduce(theta, dist, nbr=3)
        array([[-0.7853982 ,  1.5707964 ],
               [ 0.70710677,  1.        ]], dtype=float32)
        &gt;&gt;&gt; transformer.hough_reduce(theta.reshape((1, -1)), dist.reshape((1, -1)), nbr=3)
        array([array([[-0.7853982 ,  1.5707964 ],
                      [ 0.70710677,  1.        ]], dtype=float32)], dtype=object)
        &gt;&gt;&gt;

        Les dimensions de retour.
        &gt;&gt;&gt; x, y = (np.random.normal(size=(6, 5, 4)),
        ...         np.random.normal(size=(6, 5, 4)))
        &gt;&gt;&gt; theta, dist = transformer.hough(x, y)
        &gt;&gt;&gt; transformer.hough_reduce(theta, dist).shape
        (6, 5)
        &gt;&gt;&gt; 
        &#34;&#34;&#34;
        assert isinstance(theta_vect, np.ndarray), \
            f&#34;&#39;theta_vect&#39; has to be of type np.ndarray, not {type(theta_vect).__name__}.&#34;
        assert isinstance(dist_vect, np.ndarray), \
            f&#34;&#39;dist_vect&#39; has to be of type np.ndarray, not {type(dist_vect).__name__}.&#34;
        assert theta_vect.shape == dist_vect.shape, \
            f&#34;Les 2 entrees doivent avoir la meme taille: {theta_vect.shape} vs {dist_vect.shape}.&#34;
        assert theta_vect.ndim &gt;= 1, &#34;La matrice ne doit pas etre vide.&#34;
        assert isinstance(tol, float), f&#34;&#39;tol&#39; has to be a float, not a {type(tol).__name__}.&#34;
        assert 0.0 &lt; tol &lt;= 0.5, (&#34;Les valeurs coherentes de &#39;tol&#39; se trouvent entre &#34;
            f&#34;]0, 1/2], or tol vaut {tol}, ce qui sort de cet intervalle.&#34;)
        assert isinstance(nbr, int), f&#34;&#39;nbr&#39; has to be an integer, not a {type(nbr).__name__}.&#34;
        assert 2 &lt; nbr, f&#34;2 points sont toujours alignes! Vous ne pouvez pas choisir nbr={nbr}.&#34;

        # On fait la conversion des le debut pour un gain de temps.
        theta_vect, dist_vect = theta_vect.astype(np.float32, copy=False), dist_vect.astype(np.float32, copy=False)

        *over_dims, nbr_inter = theta_vect.shape # Recuperation des dimensions.
        nbr = (nbr*(nbr-1))/2 # On converti le nombre de points alignes en nbr de segments.

        # On commence par travailler avec les donnees reduites.
        theta_theo_std = math.pi / math.sqrt(3) # Variance theorique = (math.pi - -math.pi)**2 / 12
        dist_std = np.nanstd(dist_vect, axis=-1) # Ecart type non biaise (sum(*over_dims)/N), shape: (*over_dims)
        dist_vect = (dist_vect * theta_theo_std
            / np.repeat(dist_std[..., np.newaxis], nbr_inter, axis=-1)) # Les distances quasi reduites.
        
        # Extraction des clusters.
        if not len(over_dims): # Cas des tableaux 1d.
            return self._clustering_1d(theta_vect, dist_vect, dist_std, tol, nbr)

        clusters = np.empty(np.prod(over_dims, dtype=int), dtype=object) # On doit d&#39;abord creer un tableau d&#39;objet 1d.
        if multiprocessing.current_process().name == &#34;MainProcess&#34; and np.prod(over_dims) &gt;= os.cpu_count(): # Si ca vaut le coup de parraleliser:
            ser_self = cloudpickle.dumps(self) # Strategie car &#39;pickle&#39; ne sais pas faire ca.
            from laue.tools.multi_core import pickleable_method
            with multiprocessing.Pool() as pool:
                clusters[:] = pool.map(
                    pickleable_method, # Car si il y a autant de cluster dans chaque image,
                    (                   # numpy aurait envi de faire un tableau 2d plutot qu&#39;un vecteur de listes.
                        (
                            Transformer._clustering_1d,
                            ser_self,
                            {&#34;theta_vect_1d&#34;:theta, &#34;dist_vect_1d&#34;:dist, &#34;std&#34;:std, &#34;tol&#34;:tol, &#34;nbr&#34;:nbr}
                        )
                        for theta, dist, std
                        in zip(
                            theta_vect.reshape((-1, nbr_inter)),
                            dist_vect.reshape((-1, nbr_inter)),
                            np.nditer(dist_std)
                        )
                    )
                )
        else:
            clusters[:] = [self._clustering_1d(theta, dist, std, tol, nbr)
                           for theta, dist, std in zip(
                                    theta_vect.reshape((-1, nbr_inter)),
                                    dist_vect.reshape((-1, nbr_inter)),
                                    np.nditer(dist_std))] 
        clusters = clusters.reshape(over_dims) # On redimensione a la fin de sorte a garentir les dimensions.

        return clusters

    def inter_lines(self, theta_vect, dist_vect):
        r&#34;&#34;&#34;
        ** Calcul les points d&#39;intersection entre les droites. **

        Notes
        -----
        * Cette methode est concue pour traiter les donnees issues de ``laue.geometry.Transformer.hough``.
        * En raison de performance et de memoire, les calculs se font sur des float32.
        * Les indices sont agences selon l&#39;ordre defini par la fonction ``comb2ind``.

        Parameters
        ----------
        theta_vect : np.ndarray
            * Vecteur des angles compris entre [-pi, pi].
            * shape = (*over_dims, nbr_droites)
        dist_vect : np.ndarray
            * Vecteur des distances des droites a l&#39;origine comprises [0, +oo].
            * shape = (*over_dims, nbr_droites)

        Returns
        -------
        np.ndarray(dtype=float32)
            * Dans le dommaine spatial et non pas le domaine de hough, cherche
            les intersections des droites. Il y a ``n*(n-1)/2`` intersections, n etant
            le nombre de droites. donc la complexite de cette methode est en ``o(n**2)``.
            * Si les vecteurs d&#39;entre sont des vecteurs 1d (ie ``*over_dims == ()``), 
            Seront retournes le vecteur d&#39;intersection selon l&#39;axe x et le vecteur
            des intersections selon l&#39;axe y. Ces 2 vecteurs de meme taille sont concatenes
            sous la forme d&#39;une matrice de shape = ``(2, n*(n-1)/2)``.
            * Si les vecteurs d&#39;entre sont en plusieurs dimensions, seul les droites de la
            derniere dimensions se retrouvent dans la meme famille. Tous comme pour les
            vecteurs 1d, on trouve d&#39;abord les intersections selon x puis en suite selon y.
            La shape du tenseur final est donc: ** shape = ``(2, *over_dims, n*(n-1)/2)`` **.

        Examples
        -------
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; from laue.geometry import Transformer
        &gt;&gt;&gt; transformer = Transformer()
        &gt;&gt;&gt; np.random.seed(0)
        &gt;&gt;&gt; x, y = np.random.normal(size=(2, 4, 5, 6))
        &gt;&gt;&gt; theta, dist = transformer.hough(x, y)
        &gt;&gt;&gt; theta.shape
        (4, 5, 15)
        &gt;&gt;&gt; transformer.inter_lines(theta, dist).shape
        (2, 4, 5, 105)
        &gt;&gt;&gt;
        &#34;&#34;&#34;
        assert isinstance(theta_vect, np.ndarray), \
            f&#34;&#39;theta_vect&#39; has to be of type np.ndarray, not {type(theta_vect).__name__}.&#34;
        assert isinstance(dist_vect, np.ndarray), \
            f&#34;&#39;dist_vect&#39; has to be of type np.ndarray, not {type(dist_vect).__name__}.&#34;
        assert theta_vect.shape == dist_vect.shape, \
            f&#34;Les 2 entrees doivent avoir la meme taille: {theta_vect.shape} vs {dist_vect.shape}.&#34;
        assert theta_vect.ndim &gt;= 1, &#34;La matrice ne doit pas etre vide.&#34;
        assert theta_vect.shape[-1] &gt;= 2, \
            f&#34;Il doit y avoir au moins 2 droites par famille, pas {theta_vect.shape[-1]}.&#34;

        theta_vect, dist_vect = theta_vect.astype(np.float32, copy=False), dist_vect.astype(np.float32, copy=False)
        n = theta_vect.shape[-1]

        theta_1 = np.concatenate([np.repeat(theta_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
        dist_1 = np.concatenate([np.repeat(dist_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
        theta_2 = np.concatenate([theta_vect[..., i+1:] for i in range(n-1)], axis=-1)
        dist_2 = np.concatenate([dist_vect[..., i+1:] for i in range(n-1)], axis=-1)

        return self.get_fct_inter_line()(theta_1, dist_1, theta_2, dist_2)

    def _clustering_1d(self, theta_vect_1d, dist_vect_1d, std, tol, nbr):
        &#34;&#34;&#34;
        ** Help for hough_reduce. **

        * Permet de trouver les clusters d&#39;un nuage de points.
        * La projection 3d, bien que moins realiste, est 20% plus rapide que la distance reele.
        &#34;&#34;&#34;
        from sklearn.cluster import DBSCAN

        THETA_STD = np.float32(math.pi / math.sqrt(3))
        WEIGHT = 0.65 # 0 =&gt; tres souple sur les angles, 1=&gt; tres souple sur les distances.

        # On retire les droites aberantes.
        mask_to_keep = np.isfinite(theta_vect_1d) &amp; np.isfinite(dist_vect_1d)
        if not mask_to_keep.any(): # Si il ne reste plus rien.
            return np.array([], dtype=np.float32)
        theta_vect_1d, dist_vect_1d = theta_vect_1d[mask_to_keep], dist_vect_1d[mask_to_keep]

        # On passe dans un autre repere de facon a ce que -pi et pi se retrouvent a cote.
        if numexpr is not None:
            theta_x = numexpr.evaluate(&#34;2*WEIGHT*cos(theta_vect_1d)&#34;)
            theta_y = numexpr.evaluate(&#34;2*WEIGHT*sin(theta_vect_1d)&#34;)
        else:
            theta_x, theta_y = 2*WEIGHT*np.cos(theta_vect_1d), 2*WEIGHT*np.sin(theta_vect_1d)

        # Recherche des clusters.
        n_jobs = -1 if multiprocessing.current_process().name == &#34;MainProcess&#34; else 1
        db_res = DBSCAN(eps=tol, min_samples=nbr, n_jobs=n_jobs).fit(
            np.vstack((theta_x, theta_y, 2*(1-WEIGHT)*dist_vect_1d)).transpose())

        # Mise en forme des clusters.
        clusters_dict = collections.defaultdict(lambda: [])
        keep = db_res.labels_ != -1 # Les indices des clusters a garder.
        for x_cyl, y_cyl, dist, group in zip(
                theta_x[keep], theta_y[keep], dist_vect_1d[keep], db_res.labels_[keep]):
            clusters_dict[group].append((x_cyl, y_cyl, dist))

        theta = np.array([np.arccos(cluster[:, 0].mean()/(2*WEIGHT))*np.sign(cluster[:, 1].sum())
                    for cluster in map(np.array, clusters_dict.values())],
                    dtype=np.float32)
        dist = np.array([cluster[:, 2].mean()
                        for cluster in map(np.array, clusters_dict.values())],
                    dtype=np.float32) * std / THETA_STD
        return np.array([theta, dist], dtype=np.float32)

    def _hash_parameters(self, parameters):
        &#34;&#34;&#34;
        ** Hache le dictionaire des parametres. **

        * Il n&#39;y a pas de verification pour des histoires de performances.

        Parameters
        ----------
        parameters : dict
            Dictionaire des parametres issues de ``laue.tools.parsing.extract_parameters``.

        Returns
        -------
        int
            Un identifiant tq 2 dictionaires identiques renvoient le meme id.
        &#34;&#34;&#34;
        return hash(( # Il faut imperativement garantir l&#39;ordre.
            parameters[&#34;dd&#34;],
            parameters[&#34;xcen&#34;],
            parameters[&#34;ycen&#34;],
            parameters[&#34;xbet&#34;],
            parameters[&#34;xgam&#34;],
            parameters[&#34;pixelsize&#34;]))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>laue.geometry.Compilator</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="laue.geometry.Transformer.cam_to_gnomonic"><code class="name flex">
<span>def <span class="ident">cam_to_gnomonic</span></span>(<span>self, pxl_x, pxl_y, parameters)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Passe des points de la camera dans un plan gnomonic. </strong></p>
<h2 id="notes">Notes</h2>
<ul>
<li>Les calculs sont effectues avec des float32 pour des histoire de performance.</li>
<li>Cette methode va 1.8 a 3.3 fois plus vite que celle de LaueTools.</li>
<li>Contrairement a LaueTools, cette methode prend en charge les vecteurs a n dimenssions.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pxl_x</code></strong> :&ensp;<code>float, int ou np.ndarray</code></dt>
<dd>Coordonnee.s du.des pxl.s selon l'axe x dans le repere de la camera. (en pxl)</dd>
<dt><strong><code>pxl_y</code></strong> :&ensp;<code>float, int ou np.ndarray</code></dt>
<dd>Coordonnee.s du.des pxl.s selon l'axe y dans le repere de la camera. (en pxl)</dd>
<dt><strong><code>parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>Le dictionaire issue de la fonction <code><a title="laue.tools.parsing.extract_parameters" href="tools/parsing.html#laue.tools.parsing.extract_parameters">extract_parameters()</a></code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float ou np.ndarray</code></dt>
<dd>Le.s coordonnee.s x puis y du.des point.s dans le plan gnomonic eprimee.s en mm.
Les dimenssions du tableau de sortie sont les memes que celle du tableau d'entree.
shape de sortie = (2, *shape_d_entree)</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from laue.geometry import Transformer
&gt;&gt;&gt; from laue.tools.parsing import extract_parameters
&gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
&gt;&gt;&gt; transformer = Transformer()
&gt;&gt;&gt; x_cam, y_cam = np.linspace(0, 2048, 5), np.linspace(0, 2048, 5)
&gt;&gt;&gt;
&gt;&gt;&gt; transformer.cam_to_gnomonic(x_cam, y_cam, parameters).astype(np.float16)
array([[-0.5127, -0.3064,  0.    ,  0.1676,  0.1342],
       [ 0.4033,  0.287 , -0.    , -0.4832, -0.9385]], dtype=float16)
&gt;&gt;&gt;
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cam_to_gnomonic(self, pxl_x, pxl_y, parameters):
    &#34;&#34;&#34;
    ** Passe des points de la camera dans un plan gnomonic. **

    Notes
    -----
    * Les calculs sont effectues avec des float32 pour des histoire de performance.
    * Cette methode va 1.8 a 3.3 fois plus vite que celle de LaueTools.
    * Contrairement a LaueTools, cette methode prend en charge les vecteurs a n dimenssions.

    Parameters
    ----------
    pxl_x : float, int ou np.ndarray
        Coordonnee.s du.des pxl.s selon l&#39;axe x dans le repere de la camera. (en pxl)
    pxl_y : float, int ou np.ndarray
        Coordonnee.s du.des pxl.s selon l&#39;axe y dans le repere de la camera. (en pxl)
    parameters : dict
        Le dictionaire issue de la fonction ``laue.tools.parsing.extract_parameters``.

    Returns
    -------
    float ou np.ndarray
        Le.s coordonnee.s x puis y du.des point.s dans le plan gnomonic eprimee.s en mm.
        Les dimenssions du tableau de sortie sont les memes que celle du tableau d&#39;entree.
        shape de sortie = (2, *shape_d_entree)

    Examples
    -------
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; from laue.geometry import Transformer
    &gt;&gt;&gt; from laue.tools.parsing import extract_parameters
    &gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
    &gt;&gt;&gt; transformer = Transformer()
    &gt;&gt;&gt; x_cam, y_cam = np.linspace(0, 2048, 5), np.linspace(0, 2048, 5)
    &gt;&gt;&gt;
    &gt;&gt;&gt; transformer.cam_to_gnomonic(x_cam, y_cam, parameters).astype(np.float16)
    array([[-0.5127, -0.3064,  0.    ,  0.1676,  0.1342],
           [ 0.4033,  0.287 , -0.    , -0.4832, -0.9385]], dtype=float16)
    &gt;&gt;&gt;
    &#34;&#34;&#34;
    assert isinstance(pxl_x, (float, int, np.ndarray)), \
        f&#34;&#39;pxl_x&#39; can not be of type {type(pxl_x).__name__}.&#34;
    assert isinstance(pxl_y, (float, int, np.ndarray)), \
        f&#34;&#39;pxl_y&#39; can not be of type {type(pxl_y).__name__}.&#34;
    assert type(pxl_x) == type(pxl_y), \
        f&#34;Les 2 types sont differents: {type(pxl_x).__name__} vs {type(pxl_y).__name__}.&#34;
    if isinstance(pxl_x, np.ndarray):
        assert pxl_x.shape == pxl_y.shape, \
            f&#34;Ils n&#39;ont pas le meme taille: {pxl_x.shape} vs {pxl_y.shape}.&#34;
    assert isinstance(parameters, dict), (&#34;Les parametres doivent founis &#34;
        f&#34;dans un dictionaire, pas dans un {type(parameters).__name__}&#34;)
    assert set(parameters) == {&#34;dd&#34;, &#34;xbet&#34;, &#34;xgam&#34;, &#34;xcen&#34;, &#34;ycen&#34;, &#34;pixelsize&#34;}, \
        (&#34;Les clefs doivent etres &#39;dd&#39;, &#39;xbet&#39;, &#39;xgam&#39;, &#39;xcen&#39;, &#39;ycen&#39; et &#39;pixelsize&#39;. &#34;
        f&#34;Or les clefs sont {set(parameters)}.&#34;)
    assert all(isinstance(v, (float, int)) for v in parameters.values()), \
        &#34;La valeurs des parametres doivent toutes etre des nombres.&#34;

    if isinstance(pxl_x, np.ndarray):
        pxl_x, pxl_y = pxl_x.astype(np.float32, copy=False), pxl_y.astype(np.float32, copy=False)
    else:
        pxl_x, pxl_y = np.float32(pxl_x), np.float32(pxl_y)

    hash_param = self._hash_parameters(parameters) # Recuperation de la &#39;signature&#39; des parametres.
    optimized_func = self._fcts_cam_to_gnomonic[hash_param] # On regarde si il y a une fonction deja optimisee.

    if isinstance(optimized_func, int): # Si il n&#39;y a pas de fonction optimisee.
        nbr_access = optimized_func # Ce qui est enregistre et le nombre de fois que l&#39;on a chercher a y acceder.
        self._fcts_cam_to_gnomonic[hash_param] += 1 # Comme on cherche a y acceder actuelement, on peut incrementer le compteur.
        if nbr_access + 1 == 4: # Si c&#39;est la 4 eme fois qu&#39;on accede a la fonction.
            self.compile(parameters) # On optimise la fonction.
        else: # Si ce n&#39;est pas encore le moment de perdre du temps a optimiser.
            return self.get_expr_cam_to_gnomonic()(pxl_x, pxl_y,
                parameters[&#34;dd&#34;], parameters[&#34;xcen&#34;], parameters[&#34;ycen&#34;],
                parameters[&#34;xbet&#34;], parameters[&#34;xgam&#34;], parameters[&#34;pixelsize&#34;])

    return self._fcts_cam_to_gnomonic[hash_param](pxl_x, pxl_y)</code></pre>
</details>
</dd>
<dt id="laue.geometry.Transformer.dist_line"><code class="name flex">
<span>def <span class="ident">dist_line</span></span>(<span>self, theta_vect, dist_vect, x_vect, y_vect)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Calcul les distances projetees des points sur une droite. </strong></p>
<h2 id="notes">Notes</h2>
<p>Pour des raisons de performances, travail avec des float32.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>theta_vect</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Les angles des droites normales aux droites principales.
shape = <code>(*nbr_droites)</code></dd>
<dt><strong><code>dist_vect</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Les distances entre les droites et l'origine.
shape = <code>(*nbr_droites)</code></dd>
<dt><strong><code>x_vect</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>L'ensemble des coordonnees x des points.
shape = <code>(*nbr_points)</code></dd>
<dt><strong><code>y_vect</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>L'ensemble des coordonnees y des points.
shape = <code>(*nbr_points)</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Les distances des projetees des points sur chacunes des droites.
shape = <code>(*nbr_droites, *nbr_points)</code></dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from laue.geometry import Transformer
&gt;&gt;&gt; from laue.tools.parsing import extract_parameters
&gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
&gt;&gt;&gt; transformer = Transformer()
&gt;&gt;&gt;
&gt;&gt;&gt; lines = (np.array([0, np.pi/2]), np.array([1, 1])) # Horizontale et verticale passant par (1, 1)
&gt;&gt;&gt; points = (np.array([0, 1, 3, 0]), np.array([0, 1, 3, 1]))
&gt;&gt;&gt; np.round(transformer.dist_line(*lines, *points))
array([[1., 0., 2., 1.],
       [1., 0., 2., 0.]], dtype=float32)
&gt;&gt;&gt;
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dist_line(self, theta_vect, dist_vect, x_vect, y_vect):
    &#34;&#34;&#34;
    ** Calcul les distances projetees des points sur une droite. **

    Notes
    -----
    Pour des raisons de performances, travail avec des float32.

    Parameters
    ----------
    theta_vect : np.ndarray
        Les angles des droites normales aux droites principales.
        shape = ``(*nbr_droites)``
    dist_vect : np.ndarray
        Les distances entre les droites et l&#39;origine.
        shape = ``(*nbr_droites)``
    x_vect : np.ndarray
        L&#39;ensemble des coordonnees x des points.
        shape = ``(*nbr_points)``
    y_vect : np.ndarray
        L&#39;ensemble des coordonnees y des points.
        shape = ``(*nbr_points)``

    Returns
    -------
    np.ndarray
        Les distances des projetees des points sur chacunes des droites.
        shape = ``(*nbr_droites, *nbr_points)``

    Examples
    --------
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; from laue.geometry import Transformer
    &gt;&gt;&gt; from laue.tools.parsing import extract_parameters
    &gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
    &gt;&gt;&gt; transformer = Transformer()
    &gt;&gt;&gt;
    &gt;&gt;&gt; lines = (np.array([0, np.pi/2]), np.array([1, 1])) # Horizontale et verticale passant par (1, 1)
    &gt;&gt;&gt; points = (np.array([0, 1, 3, 0]), np.array([0, 1, 3, 1]))
    &gt;&gt;&gt; np.round(transformer.dist_line(*lines, *points))
    array([[1., 0., 2., 1.],
           [1., 0., 2., 0.]], dtype=float32)
    &gt;&gt;&gt;
    &#34;&#34;&#34;
    assert isinstance(theta_vect, np.ndarray), \
        f&#34;&#39;theta_vect&#39; has to be of type np.ndarray, not {type(theta_vect).__name__}.&#34;
    assert isinstance(dist_vect, np.ndarray), \
        f&#34;&#39;dist_vect&#39; has to be of type np.ndarray, not {type(dist_vect).__name__}.&#34;
    assert theta_vect.shape == dist_vect.shape, \
        f&#34;Les 2 parametres de droite doivent avoir la meme taille: {theta_vect.shape} vs {dist_vect.shape}.&#34;
    assert isinstance(x_vect, np.ndarray), \
        f&#34;&#39;x_vect&#39; has to be of type np.ndarray, not {type(x_vect).__name__}.&#34;
    assert isinstance(y_vect, np.ndarray), \
        f&#34;&#39;y_vect&#39; has to be of type np.ndarray, not {type(y_vect).__name__}.&#34;
    assert x_vect.shape == y_vect.shape, \
        f&#34;Les 2 coordonnees des points doivent avoir la meme shape: {x_vect.shape} vs {y_vect.shape}.&#34;

    theta_vect, dist_vect = theta_vect.astype(np.float32, copy=False), dist_vect.astype(np.float32, copy=False)
    x_vect, y_vect = x_vect.astype(np.float32, copy=False), y_vect.astype(np.float32, copy=False)

    nbr_droites = theta_vect.shape
    nbr_points = x_vect.shape

    # Ca ne vaut pas le coup de paralleliser car c&#39;est tres rapide.
    func = self.get_fct_dist_line()
    result = np.array([func(theta, dist, x_vect, y_vect)
                       for theta, dist
                       in zip(theta_vect.ravel(), dist_vect.ravel())
                      ], dtype=np.float32).reshape((*nbr_droites, *nbr_points))
    return result</code></pre>
</details>
</dd>
<dt id="laue.geometry.Transformer.gnomonic_to_cam"><code class="name flex">
<span>def <span class="ident">gnomonic_to_cam</span></span>(<span>self, gnom_x, gnom_y, parameters)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Passe des points du plan gnomonic vers la camera. </strong></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>gnom_x</code></strong> :&ensp;<code>float ou np.ndarray</code></dt>
<dd>Coordonnee.s du.des point.s selon l'axe x du repere du plan gnomonic. (en mm)</dd>
<dt><strong><code>gnom_y</code></strong> :&ensp;<code>float ou np.ndarray</code></dt>
<dd>Coordonnee.s du.des point.s selon l'axe y du repere du plan gnomonic. (en mm)</dd>
<dt><strong><code>parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>Le dictionaire issue de la fonction <code><a title="laue.tools.parsing.extract_parameters" href="tools/parsing.html#laue.tools.parsing.extract_parameters">extract_parameters()</a></code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>coords</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>
<ul>
<li>Le.s coordonnee.s x puis y du.des point.s dans le plan de la camera. (en pxl)</li>
<li>shape = (2, &hellip;)</li>
</ul>
</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from laue.geometry import Transformer
&gt;&gt;&gt; from laue.tools.parsing import extract_parameters
&gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
&gt;&gt;&gt; transformer = Transformer()
&gt;&gt;&gt; gnom_x, gnom_y = np.random.normal(size=(2, 10, 4))
&gt;&gt;&gt;
&gt;&gt;&gt; transformer.gnomonic_to_cam(gnom_x, gnom_y, parameters).shape
(2, 10, 4)
&gt;&gt;&gt; transformer.gnomonic_to_cam(.0, .0, parameters)
array([1024., 1024.])
&gt;&gt;&gt;
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gnomonic_to_cam(self, gnom_x, gnom_y, parameters):
    &#34;&#34;&#34;
    ** Passe des points du plan gnomonic vers la camera. **

    Parameters
    ----------
    gnom_x : float ou np.ndarray
        Coordonnee.s du.des point.s selon l&#39;axe x du repere du plan gnomonic. (en mm)
    gnom_y : float ou np.ndarray
        Coordonnee.s du.des point.s selon l&#39;axe y du repere du plan gnomonic. (en mm)
    parameters : dict
        Le dictionaire issue de la fonction ``laue.tools.parsing.extract_parameters``.

    Returns
    -------
    coords : np.ndarray
        * Le.s coordonnee.s x puis y du.des point.s dans le plan de la camera. (en pxl)
        * shape = (2, ...)

    Examples
    -------
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; from laue.geometry import Transformer
    &gt;&gt;&gt; from laue.tools.parsing import extract_parameters
    &gt;&gt;&gt; parameters = extract_parameters(dd=70, bet=.0, gam=.0, pixelsize=.08, x0=1024, y0=1024)
    &gt;&gt;&gt; transformer = Transformer()
    &gt;&gt;&gt; gnom_x, gnom_y = np.random.normal(size=(2, 10, 4))
    &gt;&gt;&gt;
    &gt;&gt;&gt; transformer.gnomonic_to_cam(gnom_x, gnom_y, parameters).shape
    (2, 10, 4)
    &gt;&gt;&gt; transformer.gnomonic_to_cam(.0, .0, parameters)
    array([1024., 1024.])
    &gt;&gt;&gt;
    &#34;&#34;&#34;
    assert isinstance(gnom_x, (float, int, np.ndarray)), \
        f&#34;&#39;gnom_x&#39; can not be of type {type(gnom_x).__name__}.&#34;
    assert isinstance(gnom_y, (float, int, np.ndarray)), \
        f&#34;&#39;gnom_y&#39; can not be of type {type(gnom_y).__name__}.&#34;
    assert type(gnom_x) == type(gnom_y), \
        f&#34;Les 2 types sont differents: {type(gnom_x).__name__} vs {type(gnom_y).__name__}.&#34;
    if isinstance(gnom_x, np.ndarray):
        assert gnom_x.shape == gnom_y.shape, \
            f&#34;Ils n&#39;ont pas la meme taille: {gnom_x.shape} vs {gnom_y.shape}.&#34;
    assert isinstance(parameters, dict), (&#34;Les parametres doivent founis &#34;
        f&#34;dans un dictionaire, pas dans un {type(parameters).__name__}&#34;)
    assert set(parameters) == {&#34;dd&#34;, &#34;xbet&#34;, &#34;xgam&#34;, &#34;xcen&#34;, &#34;ycen&#34;, &#34;pixelsize&#34;}, \
        (&#34;Les clefs doivent etres &#39;dd&#39;, &#39;xbet&#39;, &#39;xgam&#39;, &#39;xcen&#39;, &#39;ycen&#39; et &#39;pixelsize&#39;. &#34;
        f&#34;Or les clefs sont {set(parameters)}.&#34;)
    assert all(isinstance(v, (float, int)) for v in parameters.values()), \
        &#34;La valeurs des parametres doivent toutes etre des nombres.&#34;

    if isinstance(gnom_x, np.ndarray):
        gnom_x, gnom_y = gnom_x.astype(np.float32, copy=False), gnom_y.astype(np.float32, copy=False)
    else:
        gnom_x, gnom_y = np.float32(gnom_x), np.float32(gnom_y)

    hash_param = self._hash_parameters(parameters) # Recuperation de la &#39;signature&#39; des parametres.
    optimized_func = self._fcts_gnomonic_to_cam[hash_param] # On regarde si il y a une fonction deja optimisee.

    if isinstance(optimized_func, int): # Si il n&#39;y a pas de fonction optimisee.
        nbr_access = optimized_func # Ce qui est enregistre et le nombre de fois que l&#39;on a chercher a y acceder.
        self._fcts_gnomonic_to_cam[hash_param] += 1 # Comme on cherche a y acceder actuelement, on peut incrementer le compteur.
        if nbr_access + 1 == 4: # Si c&#39;est la 4 eme fois qu&#39;on accede a la fonction.
            self.compile(parameters) # On optimise la fonction.
        else: # Si ce n&#39;est pas encore le moment de perdre du temps a optimiser.
            return self.get_expr_gnomonic_to_cam()(gnom_x, gnom_y,
                parameters[&#34;dd&#34;], parameters[&#34;xcen&#34;], parameters[&#34;ycen&#34;],
                parameters[&#34;xbet&#34;], parameters[&#34;xgam&#34;], parameters[&#34;pixelsize&#34;])

    return self._fcts_gnomonic_to_cam[hash_param](gnom_x, gnom_y)</code></pre>
</details>
</dd>
<dt id="laue.geometry.Transformer.hough"><code class="name flex">
<span>def <span class="ident">hough</span></span>(<span>self, x_vect, y_vect)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Transformee de hough avec des droites. </strong></p>
<h2 id="note">Note</h2>
<ul>
<li>Pour des raisons de performances, les calculs se font sur des float32.</li>
<li>Les indices sont agences selon l'ordre defini par la fonction <code><a title="laue.geometry.comb2ind" href="#laue.geometry.comb2ind">comb2ind()</a></code>.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x_vect</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>L'ensemble des coordonnees x des points de shape: (*over_dims, nbr_points)</dd>
<dt><strong><code>y_vect</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>L'ensemble des coordonnees y des points de shape: (*over_dims, nbr_points)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>theta</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>
<ul>
<li>Les angles au sens trigomometrique des vecteurs reliant l'origine
<code>O</code> (0, 0) au point <code>P</code> appartenant a la droite tel que <code>||OP||</code>
soit la plus petite possible.</li>
<li>theta € [-pi, pi]</li>
<li>shape = <code>(*over_dims, n*(n-1)/2)</code></li>
</ul>
</dd>
<dt><strong><code>dist</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>
<ul>
<li>Ce sont les normes des vecteur <code>OP</code>.</li>
<li>dist € [0, +oo].</li>
<li>shape = <code>(*over_dims, n*(n-1)/2)</code></li>
</ul>
</dd>
</dl>
<ul>
<li>Ces 2 grandeurs sont concatenees dans une seule array de
shape = <code>(2, *over_dims, n*(n-1)/2)</code></li>
</ul>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from laue import geometry
&gt;&gt;&gt; transformer = geometry.Transformer()
&gt;&gt;&gt; x, y = np.random.normal(size=(2, 6))
&gt;&gt;&gt; transformer.hough(x, y).shape
(2, 15)
&gt;&gt;&gt;
&gt;&gt;&gt; x, y = np.random.normal(size=(2, 4, 5, 6))
&gt;&gt;&gt; transformer.hough(x, y).shape
(2, 4, 5, 15)
&gt;&gt;&gt;
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hough(self, x_vect, y_vect):
    r&#34;&#34;&#34;
    ** Transformee de hough avec des droites. **

    Note
    ----
    * Pour des raisons de performances, les calculs se font sur des float32.
    * Les indices sont agences selon l&#39;ordre defini par la fonction ``comb2ind``.

    Parameters
    ----------
    x_vect : np.ndarray
        L&#39;ensemble des coordonnees x des points de shape: (*over_dims, nbr_points)
    y_vect : np.ndarray
        L&#39;ensemble des coordonnees y des points de shape: (*over_dims, nbr_points)

    Returns
    -------
    theta : np.ndarray
        * Les angles au sens trigomometrique des vecteurs reliant l&#39;origine
        ``O`` (0, 0) au point ``P`` appartenant a la droite tel que ``||OP||``
        soit la plus petite possible.
        * theta € [-pi, pi]
        * shape = ``(*over_dims, n*(n-1)/2)``
    dist : np.ndarray
        * Ce sont les normes des vecteur ``OP``.
        * dist € [0, +oo].
        * shape = ``(*over_dims, n*(n-1)/2)``
    * Ces 2 grandeurs sont concatenees dans une seule array de
    shape = ``(2, *over_dims, n*(n-1)/2)``

    Examples
    --------
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; from laue import geometry
    &gt;&gt;&gt; transformer = geometry.Transformer()
    &gt;&gt;&gt; x, y = np.random.normal(size=(2, 6))
    &gt;&gt;&gt; transformer.hough(x, y).shape
    (2, 15)
    &gt;&gt;&gt;
    &gt;&gt;&gt; x, y = np.random.normal(size=(2, 4, 5, 6))
    &gt;&gt;&gt; transformer.hough(x, y).shape
    (2, 4, 5, 15)
    &gt;&gt;&gt; 
    &#34;&#34;&#34;
    assert isinstance(x_vect, np.ndarray), \
        f&#34;&#39;x_vect&#39; has to be of type np.ndarray, not {type(x_vect).__name__}.&#34;
    assert isinstance(y_vect, np.ndarray), \
        f&#34;&#39;y_vect&#39; has to be of type np.ndarray, not {type(y_vect).__name__}.&#34;
    assert x_vect.shape == y_vect.shape, \
        f&#34;Les 2 entrees doivent avoir la meme taille: {x_vect.shape} vs {y_vect.shape}.&#34;

    n = x_vect.shape[-1]
    x_vect, y_vect = x_vect.astype(np.float32, copy=False), y_vect.astype(np.float32, copy=False)

    xa = np.concatenate([np.repeat(x_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
    ya = np.concatenate([np.repeat(y_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
    xb = np.concatenate([x_vect[..., i+1:] for i in range(n-1)], axis=-1)
    yb = np.concatenate([y_vect[..., i+1:] for i in range(n-1)], axis=-1)

    return np.nan_to_num(
        self.get_fct_hough()(xa, ya, xb, yb),
        copy=False,
        nan=0.0)</code></pre>
</details>
</dd>
<dt id="laue.geometry.Transformer.hough_reduce"><code class="name flex">
<span>def <span class="ident">hough_reduce</span></span>(<span>self, theta_vect, dist_vect, *, nbr=4, tol=0.018)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Regroupe des droites ressemblantes. </strong></p>
<h2 id="notes">Notes</h2>
<ul>
<li>Cette methode est concue pour traiter les donnees issues de <code><a title="laue.geometry.Transformer.hough" href="#laue.geometry.Transformer.hough">Transformer.hough()</a></code>.</li>
<li>La metrique utilise est la distance euclidiene sur un cylindre ferme sur theta.</li>
<li>En raison de performance et de memoire, les calculs se font sur des float32.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>theta_vect</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>
<ul>
<li>Vecteur des angles compris entre [-pi, pi].</li>
<li>shape = <code>(*over_dims, nbr_inter)</code></li>
</ul>
</dd>
<dt><strong><code>dist_vect</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>
<ul>
<li>Vecteur des distances des droites a l'origine comprises [0, +oo].</li>
<li>shape = <code>(*over_dims, nbr_inter)</code></li>
</ul>
</dd>
<dt><strong><code>tol</code></strong> :&ensp;<code>float</code></dt>
<dd>La distance maximal separant 2 points dans l'espace de hough reduit,
(ie la difference entre 2 droites dans l'espace spacial) tel que les points
se retrouvent dans le meme cluster. Plus ce nombre est petit, plus les points
doivent etre bien alignes. C'est une sorte de tolerance sur l'alignement.</dd>
<dt><strong><code>nbr</code></strong> :&ensp;<code>int</code></dt>
<dd>C'est le nombre minimum de points presque alignes pour que
l'on puisse considerer la droite qui passe par ces points.
Par defaut, les droites qui ne passent que par 4 points et plus sont retenues.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray(dtype=float32), np.ndarray(dtype=object)</code></dt>
<dd>
<ul>
<li>Ce sont les centres des clusters pour chaque 'nuages de points'. Cela correspond
aux angles et aux distances qui caracterisent chaque droites.</li>
<li>Si les parametres d'entres sont des vecteurs 1d, le resultat sera une array
numpy contenant les <strong>angles</strong> puis les <strong>distances</strong>. Donc de shape = <code>(2, nbr_clusters)</code></li>
<li>Si les parametres d'entres sont en plusieur dimensions, (representes plusieur
nuages de points indepandant), alors le resultat sera une array d'objet de
shape = <code>(*over_dims)</code>. Chaque objet est lui meme un array, resultat recursif
de l'appel de cette fonction sur le nuage de points unique correspondant.</li>
</ul>
</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from laue import geometry
&gt;&gt;&gt; transformer = geometry.Transformer()
</code></pre>
<p>Type de retour <code>np.float32</code> vs <code>object</code>.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; x, y = (np.array([ 1.,  2.,  3.,  0., -1.]),
...         np.array([ 0.,  1.,  1., -1.,  1.]))
&gt;&gt;&gt; theta, dist = transformer.hough(x, y)
&gt;&gt;&gt; transformer.hough_reduce(theta, dist, nbr=3)
array([[-0.7853982 ,  1.5707964 ],
       [ 0.70710677,  1.        ]], dtype=float32)
&gt;&gt;&gt; transformer.hough_reduce(theta.reshape((1, -1)), dist.reshape((1, -1)), nbr=3)
array([array([[-0.7853982 ,  1.5707964 ],
              [ 0.70710677,  1.        ]], dtype=float32)], dtype=object)
&gt;&gt;&gt;
</code></pre>
<p>Les dimensions de retour.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; x, y = (np.random.normal(size=(6, 5, 4)),
...         np.random.normal(size=(6, 5, 4)))
&gt;&gt;&gt; theta, dist = transformer.hough(x, y)
&gt;&gt;&gt; transformer.hough_reduce(theta, dist).shape
(6, 5)
&gt;&gt;&gt;
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hough_reduce(self, theta_vect, dist_vect, *, nbr=4, tol=0.018):
    &#34;&#34;&#34;
    ** Regroupe des droites ressemblantes. **

    Notes
    -----
    * Cette methode est concue pour traiter les donnees issues de ``laue.geometry.Transformer.hough``.
    * La metrique utilise est la distance euclidiene sur un cylindre ferme sur theta.
    * En raison de performance et de memoire, les calculs se font sur des float32.

    Parameters
    ----------
    theta_vect : np.ndarray
        * Vecteur des angles compris entre [-pi, pi].
        * shape = ``(*over_dims, nbr_inter)``
    dist_vect : np.ndarray
        * Vecteur des distances des droites a l&#39;origine comprises [0, +oo].
        * shape = ``(*over_dims, nbr_inter)``
    tol : float
        La distance maximal separant 2 points dans l&#39;espace de hough reduit,
        (ie la difference entre 2 droites dans l&#39;espace spacial) tel que les points
        se retrouvent dans le meme cluster. Plus ce nombre est petit, plus les points
        doivent etre bien alignes. C&#39;est une sorte de tolerance sur l&#39;alignement.
    nbr : int
        C&#39;est le nombre minimum de points presque alignes pour que
        l&#39;on puisse considerer la droite qui passe par ces points.
        Par defaut, les droites qui ne passent que par 4 points et plus sont retenues.

    Returns
    -------
    np.ndarray(dtype=float32), np.ndarray(dtype=object)
        * Ce sont les centres des clusters pour chaque &#39;nuages de points&#39;. Cela correspond
        aux angles et aux distances qui caracterisent chaque droites.
        * Si les parametres d&#39;entres sont des vecteurs 1d, le resultat sera une array
        numpy contenant les **angles** puis les **distances**. Donc de shape = ``(2, nbr_clusters)``
        * Si les parametres d&#39;entres sont en plusieur dimensions, (representes plusieur
        nuages de points indepandant), alors le resultat sera une array d&#39;objet de
        shape = ``(*over_dims)``. Chaque objet est lui meme un array, resultat recursif
        de l&#39;appel de cette fonction sur le nuage de points unique correspondant.

    Examples
    --------
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; from laue import geometry
    &gt;&gt;&gt; transformer = geometry.Transformer()

    Type de retour ``np.float32`` vs ``object``.
    &gt;&gt;&gt; x, y = (np.array([ 1.,  2.,  3.,  0., -1.]),
    ...         np.array([ 0.,  1.,  1., -1.,  1.]))
    &gt;&gt;&gt; theta, dist = transformer.hough(x, y)
    &gt;&gt;&gt; transformer.hough_reduce(theta, dist, nbr=3)
    array([[-0.7853982 ,  1.5707964 ],
           [ 0.70710677,  1.        ]], dtype=float32)
    &gt;&gt;&gt; transformer.hough_reduce(theta.reshape((1, -1)), dist.reshape((1, -1)), nbr=3)
    array([array([[-0.7853982 ,  1.5707964 ],
                  [ 0.70710677,  1.        ]], dtype=float32)], dtype=object)
    &gt;&gt;&gt;

    Les dimensions de retour.
    &gt;&gt;&gt; x, y = (np.random.normal(size=(6, 5, 4)),
    ...         np.random.normal(size=(6, 5, 4)))
    &gt;&gt;&gt; theta, dist = transformer.hough(x, y)
    &gt;&gt;&gt; transformer.hough_reduce(theta, dist).shape
    (6, 5)
    &gt;&gt;&gt; 
    &#34;&#34;&#34;
    assert isinstance(theta_vect, np.ndarray), \
        f&#34;&#39;theta_vect&#39; has to be of type np.ndarray, not {type(theta_vect).__name__}.&#34;
    assert isinstance(dist_vect, np.ndarray), \
        f&#34;&#39;dist_vect&#39; has to be of type np.ndarray, not {type(dist_vect).__name__}.&#34;
    assert theta_vect.shape == dist_vect.shape, \
        f&#34;Les 2 entrees doivent avoir la meme taille: {theta_vect.shape} vs {dist_vect.shape}.&#34;
    assert theta_vect.ndim &gt;= 1, &#34;La matrice ne doit pas etre vide.&#34;
    assert isinstance(tol, float), f&#34;&#39;tol&#39; has to be a float, not a {type(tol).__name__}.&#34;
    assert 0.0 &lt; tol &lt;= 0.5, (&#34;Les valeurs coherentes de &#39;tol&#39; se trouvent entre &#34;
        f&#34;]0, 1/2], or tol vaut {tol}, ce qui sort de cet intervalle.&#34;)
    assert isinstance(nbr, int), f&#34;&#39;nbr&#39; has to be an integer, not a {type(nbr).__name__}.&#34;
    assert 2 &lt; nbr, f&#34;2 points sont toujours alignes! Vous ne pouvez pas choisir nbr={nbr}.&#34;

    # On fait la conversion des le debut pour un gain de temps.
    theta_vect, dist_vect = theta_vect.astype(np.float32, copy=False), dist_vect.astype(np.float32, copy=False)

    *over_dims, nbr_inter = theta_vect.shape # Recuperation des dimensions.
    nbr = (nbr*(nbr-1))/2 # On converti le nombre de points alignes en nbr de segments.

    # On commence par travailler avec les donnees reduites.
    theta_theo_std = math.pi / math.sqrt(3) # Variance theorique = (math.pi - -math.pi)**2 / 12
    dist_std = np.nanstd(dist_vect, axis=-1) # Ecart type non biaise (sum(*over_dims)/N), shape: (*over_dims)
    dist_vect = (dist_vect * theta_theo_std
        / np.repeat(dist_std[..., np.newaxis], nbr_inter, axis=-1)) # Les distances quasi reduites.
    
    # Extraction des clusters.
    if not len(over_dims): # Cas des tableaux 1d.
        return self._clustering_1d(theta_vect, dist_vect, dist_std, tol, nbr)

    clusters = np.empty(np.prod(over_dims, dtype=int), dtype=object) # On doit d&#39;abord creer un tableau d&#39;objet 1d.
    if multiprocessing.current_process().name == &#34;MainProcess&#34; and np.prod(over_dims) &gt;= os.cpu_count(): # Si ca vaut le coup de parraleliser:
        ser_self = cloudpickle.dumps(self) # Strategie car &#39;pickle&#39; ne sais pas faire ca.
        from laue.tools.multi_core import pickleable_method
        with multiprocessing.Pool() as pool:
            clusters[:] = pool.map(
                pickleable_method, # Car si il y a autant de cluster dans chaque image,
                (                   # numpy aurait envi de faire un tableau 2d plutot qu&#39;un vecteur de listes.
                    (
                        Transformer._clustering_1d,
                        ser_self,
                        {&#34;theta_vect_1d&#34;:theta, &#34;dist_vect_1d&#34;:dist, &#34;std&#34;:std, &#34;tol&#34;:tol, &#34;nbr&#34;:nbr}
                    )
                    for theta, dist, std
                    in zip(
                        theta_vect.reshape((-1, nbr_inter)),
                        dist_vect.reshape((-1, nbr_inter)),
                        np.nditer(dist_std)
                    )
                )
            )
    else:
        clusters[:] = [self._clustering_1d(theta, dist, std, tol, nbr)
                       for theta, dist, std in zip(
                                theta_vect.reshape((-1, nbr_inter)),
                                dist_vect.reshape((-1, nbr_inter)),
                                np.nditer(dist_std))] 
    clusters = clusters.reshape(over_dims) # On redimensione a la fin de sorte a garentir les dimensions.

    return clusters</code></pre>
</details>
</dd>
<dt id="laue.geometry.Transformer.inter_lines"><code class="name flex">
<span>def <span class="ident">inter_lines</span></span>(<span>self, theta_vect, dist_vect)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Calcul les points d'intersection entre les droites. </strong></p>
<h2 id="notes">Notes</h2>
<ul>
<li>Cette methode est concue pour traiter les donnees issues de <code><a title="laue.geometry.Transformer.hough" href="#laue.geometry.Transformer.hough">Transformer.hough()</a></code>.</li>
<li>En raison de performance et de memoire, les calculs se font sur des float32.</li>
<li>Les indices sont agences selon l'ordre defini par la fonction <code><a title="laue.geometry.comb2ind" href="#laue.geometry.comb2ind">comb2ind()</a></code>.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>theta_vect</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>
<ul>
<li>Vecteur des angles compris entre [-pi, pi].</li>
<li>shape = (*over_dims, nbr_droites)</li>
</ul>
</dd>
<dt><strong><code>dist_vect</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>
<ul>
<li>Vecteur des distances des droites a l'origine comprises [0, +oo].</li>
<li>shape = (*over_dims, nbr_droites)</li>
</ul>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray(dtype=float32)</code></dt>
<dd>
<ul>
<li>Dans le dommaine spatial et non pas le domaine de hough, cherche
les intersections des droites. Il y a <code>n*(n-1)/2</code> intersections, n etant
le nombre de droites. donc la complexite de cette methode est en <code>o(n**2)</code>.</li>
<li>Si les vecteurs d'entre sont des vecteurs 1d (ie <code>*over_dims == ()</code>),
Seront retournes le vecteur d'intersection selon l'axe x et le vecteur
des intersections selon l'axe y. Ces 2 vecteurs de meme taille sont concatenes
sous la forme d'une matrice de shape = <code>(2, n*(n-1)/2)</code>.</li>
<li>Si les vecteurs d'entre sont en plusieurs dimensions, seul les droites de la
derniere dimensions se retrouvent dans la meme famille. Tous comme pour les
vecteurs 1d, on trouve d'abord les intersections selon x puis en suite selon y.
La shape du tenseur final est donc: <strong> shape = <code>(2, *over_dims, n*(n-1)/2)</code> </strong>.</li>
</ul>
</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from laue.geometry import Transformer
&gt;&gt;&gt; transformer = Transformer()
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; x, y = np.random.normal(size=(2, 4, 5, 6))
&gt;&gt;&gt; theta, dist = transformer.hough(x, y)
&gt;&gt;&gt; theta.shape
(4, 5, 15)
&gt;&gt;&gt; transformer.inter_lines(theta, dist).shape
(2, 4, 5, 105)
&gt;&gt;&gt;
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inter_lines(self, theta_vect, dist_vect):
    r&#34;&#34;&#34;
    ** Calcul les points d&#39;intersection entre les droites. **

    Notes
    -----
    * Cette methode est concue pour traiter les donnees issues de ``laue.geometry.Transformer.hough``.
    * En raison de performance et de memoire, les calculs se font sur des float32.
    * Les indices sont agences selon l&#39;ordre defini par la fonction ``comb2ind``.

    Parameters
    ----------
    theta_vect : np.ndarray
        * Vecteur des angles compris entre [-pi, pi].
        * shape = (*over_dims, nbr_droites)
    dist_vect : np.ndarray
        * Vecteur des distances des droites a l&#39;origine comprises [0, +oo].
        * shape = (*over_dims, nbr_droites)

    Returns
    -------
    np.ndarray(dtype=float32)
        * Dans le dommaine spatial et non pas le domaine de hough, cherche
        les intersections des droites. Il y a ``n*(n-1)/2`` intersections, n etant
        le nombre de droites. donc la complexite de cette methode est en ``o(n**2)``.
        * Si les vecteurs d&#39;entre sont des vecteurs 1d (ie ``*over_dims == ()``), 
        Seront retournes le vecteur d&#39;intersection selon l&#39;axe x et le vecteur
        des intersections selon l&#39;axe y. Ces 2 vecteurs de meme taille sont concatenes
        sous la forme d&#39;une matrice de shape = ``(2, n*(n-1)/2)``.
        * Si les vecteurs d&#39;entre sont en plusieurs dimensions, seul les droites de la
        derniere dimensions se retrouvent dans la meme famille. Tous comme pour les
        vecteurs 1d, on trouve d&#39;abord les intersections selon x puis en suite selon y.
        La shape du tenseur final est donc: ** shape = ``(2, *over_dims, n*(n-1)/2)`` **.

    Examples
    -------
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; from laue.geometry import Transformer
    &gt;&gt;&gt; transformer = Transformer()
    &gt;&gt;&gt; np.random.seed(0)
    &gt;&gt;&gt; x, y = np.random.normal(size=(2, 4, 5, 6))
    &gt;&gt;&gt; theta, dist = transformer.hough(x, y)
    &gt;&gt;&gt; theta.shape
    (4, 5, 15)
    &gt;&gt;&gt; transformer.inter_lines(theta, dist).shape
    (2, 4, 5, 105)
    &gt;&gt;&gt;
    &#34;&#34;&#34;
    assert isinstance(theta_vect, np.ndarray), \
        f&#34;&#39;theta_vect&#39; has to be of type np.ndarray, not {type(theta_vect).__name__}.&#34;
    assert isinstance(dist_vect, np.ndarray), \
        f&#34;&#39;dist_vect&#39; has to be of type np.ndarray, not {type(dist_vect).__name__}.&#34;
    assert theta_vect.shape == dist_vect.shape, \
        f&#34;Les 2 entrees doivent avoir la meme taille: {theta_vect.shape} vs {dist_vect.shape}.&#34;
    assert theta_vect.ndim &gt;= 1, &#34;La matrice ne doit pas etre vide.&#34;
    assert theta_vect.shape[-1] &gt;= 2, \
        f&#34;Il doit y avoir au moins 2 droites par famille, pas {theta_vect.shape[-1]}.&#34;

    theta_vect, dist_vect = theta_vect.astype(np.float32, copy=False), dist_vect.astype(np.float32, copy=False)
    n = theta_vect.shape[-1]

    theta_1 = np.concatenate([np.repeat(theta_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
    dist_1 = np.concatenate([np.repeat(dist_vect[..., i, np.newaxis], n-i-1, axis=-1) for i in range(n-1)], axis=-1)
    theta_2 = np.concatenate([theta_vect[..., i+1:] for i in range(n-1)], axis=-1)
    dist_2 = np.concatenate([dist_vect[..., i+1:] for i in range(n-1)], axis=-1)

    return self.get_fct_inter_line()(theta_1, dist_1, theta_2, dist_2)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#permet-dappliquer-des-transformations-geometriques">Permet d'appliquer des transformations geometriques.</a></li>
<li><a href="#notes">Notes</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="laue" href="index.html">laue</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="laue.geometry.comb2ind" href="#laue.geometry.comb2ind">comb2ind</a></code></li>
<li><code><a title="laue.geometry.ind2comb" href="#laue.geometry.ind2comb">ind2comb</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="laue.geometry.Transformer" href="#laue.geometry.Transformer">Transformer</a></code></h4>
<ul class="two-column">
<li><code><a title="laue.geometry.Transformer.cam_to_gnomonic" href="#laue.geometry.Transformer.cam_to_gnomonic">cam_to_gnomonic</a></code></li>
<li><code><a title="laue.geometry.Transformer.dist_line" href="#laue.geometry.Transformer.dist_line">dist_line</a></code></li>
<li><code><a title="laue.geometry.Transformer.gnomonic_to_cam" href="#laue.geometry.Transformer.gnomonic_to_cam">gnomonic_to_cam</a></code></li>
<li><code><a title="laue.geometry.Transformer.hough" href="#laue.geometry.Transformer.hough">hough</a></code></li>
<li><code><a title="laue.geometry.Transformer.hough_reduce" href="#laue.geometry.Transformer.hough_reduce">hough_reduce</a></code></li>
<li><code><a title="laue.geometry.Transformer.inter_lines" href="#laue.geometry.Transformer.inter_lines">inter_lines</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>